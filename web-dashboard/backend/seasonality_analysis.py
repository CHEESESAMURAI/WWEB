import aiohttp
import logging
import asyncio
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from config import MPSTATS_API_KEY  # type: ignore

logger = logging.getLogger(__name__)

# Russian holidays and important dates
RUSSIAN_HOLIDAYS = {
    "01-01": "–ù–æ–≤—ã–π –≥–æ–¥", "01-02": "–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –∫–∞–Ω–∏–∫—É–ª—ã", "01-03": "–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –∫–∞–Ω–∏–∫—É–ª—ã",
    "01-04": "–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –∫–∞–Ω–∏–∫—É–ª—ã", "01-05": "–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –∫–∞–Ω–∏–∫—É–ª—ã", "01-06": "–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –∫–∞–Ω–∏–∫—É–ª—ã", 
    "01-07": "–†–æ–∂–¥–µ—Å—Ç–≤–æ", "01-08": "–ù–æ–≤–æ–≥–æ–¥–Ω–∏–µ –∫–∞–Ω–∏–∫—É–ª—ã",
    "02-23": "–î–µ–Ω—å –∑–∞—â–∏—Ç–Ω–∏–∫–∞ –û—Ç–µ—á–µ—Å—Ç–≤–∞", "03-08": "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π –∂–µ–Ω—Å–∫–∏–π –¥–µ–Ω—å",
    "05-01": "–ü—Ä–∞–∑–¥–Ω–∏–∫ –í–µ—Å–Ω—ã –∏ –¢—Ä—É–¥–∞", "05-09": "–î–µ–Ω—å –ü–æ–±–µ–¥—ã", "06-12": "–î–µ–Ω—å –†–æ—Å—Å–∏–∏",
    "11-04": "–î–µ–Ω—å –Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –µ–¥–∏–Ω—Å—Ç–≤–∞", "12-31": "–ù–æ–≤—ã–π –≥–æ–¥"
}

# Weekly seasonal patterns by category type
CATEGORY_PATTERNS = {
    "fashion": {"peak_months": [9, 10, 11, 12], "low_months": [6, 7, 8]},
    "home": {"peak_months": [3, 4, 5, 10], "low_months": [1, 2, 7]},
    "electronics": {"peak_months": [11, 12, 1], "low_months": [6, 7, 8]},
    "beauty": {"peak_months": [3, 8, 12], "low_months": [1, 6, 9]},
    "toys": {"peak_months": [11, 12, 1], "low_months": [6, 7, 8]},
    "default": {"peak_months": [11, 12], "low_months": [1, 2]}
}

async def _fetch(url: str, params: Dict[str, Any]) -> Any:
    """Utility for GET requests with MPSTATS token."""
    headers = {
        "X-Mpstats-TOKEN": MPSTATS_API_KEY,
        "Content-Type": "application/json",
    }
    async with aiohttp.ClientSession() as session:
        async with session.get(url, params=params, headers=headers) as resp:
            if resp.status == 200:
                return await resp.json()
            text = await resp.text()
            logger.error("MPSTATS API error %s ‚Äì %s", resp.status, text)
            return {"error": f"MPSTATS API error: {resp.status}"}


async def get_seasonality_annual_data(category_path: str, period: str = "day"):
    """Return annual seasonality data from MPSTATS for the given WB category path."""
    url = "https://mpstats.io/api/wb/get/ds/category/annual"
    params = {"path": category_path, "period": period}
    return await _fetch(url, params)


async def get_seasonality_weekly_data(category_path: str):
    """Return weekly seasonality data from MPSTATS for the given WB category path."""
    url = "https://mpstats.io/api/wb/get/ds/category/weekly"
    params = {"path": category_path}
    return await _fetch(url, params)


def _classify_category(category_path: str) -> str:
    """Classify category for seasonal pattern analysis."""
    category_lower = category_path.lower()
    if any(word in category_lower for word in ["–æ–¥–µ–∂–¥–∞", "–ø–ª–∞—Ç—å—è", "–æ–±—É–≤—å", "–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã", "—Å—É–º–∫–∏"]):
        return "fashion"
    elif any(word in category_lower for word in ["–¥–æ–º", "—Å–∞–¥", "–º–µ–±–µ–ª—å", "–¥–µ–∫–æ—Ä", "–∫—É—Ö–Ω—è"]):
        return "home"
    elif any(word in category_lower for word in ["—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞", "–≥–∞–¥–∂–µ—Ç—ã", "—Ç–µ–ª–µ—Ñ–æ–Ω", "–ø–ª–∞–Ω—à–µ—Ç"]):
        return "electronics"
    elif any(word in category_lower for word in ["–∫—Ä–∞—Å–æ—Ç–∞", "–∫–æ—Å–º–µ—Ç–∏–∫–∞", "–ø–∞—Ä—Ñ—é–º", "—É—Ö–æ–¥"]):
        return "beauty"
    elif any(word in category_lower for word in ["–∏–≥—Ä—É—à–∫–∏", "–¥–µ—Ç—Å–∫–∏–µ", "—Ä–∞–∑–≤–∏–≤–∞—é—â–∏–µ"]):
        return "toys"
    return "default"


def _generate_enhanced_analytics(annual_data: List[Dict], weekly_data: List[Dict], category_path: str) -> Dict[str, Any]:
    """Generate comprehensive seasonality analytics."""
    analytics = {
        "category_type": _classify_category(category_path),
        "monthly_stats": {},
        "weekly_stats": {},
        "trends": {},
        "holiday_correlation": {},
        "forecasting": {},
        "recommendations": []
    }
    
    # Monthly aggregation and analytics
    if annual_data:
        monthly_revenue = {}
        monthly_sales = {}
        holiday_boosts = []
        
        for item in annual_data:
            if item.get("noyeardate"):
                try:
                    # Parse date (format: MM-DD)
                    month = int(item["noyeardate"].split("-")[0])
                    revenue = item.get("season_revenue", 0)
                    sales = item.get("season_sales", 0)
                    
                    if month not in monthly_revenue:
                        monthly_revenue[month] = []
                        monthly_sales[month] = []
                    
                    monthly_revenue[month].append(revenue)
                    monthly_sales[month].append(sales)
                    
                    # Check for holiday correlation
                    if item["noyeardate"] in RUSSIAN_HOLIDAYS:
                        holiday_name = RUSSIAN_HOLIDAYS[item["noyeardate"]]
                        holiday_boosts.append({
                            "date": item["noyeardate"],
                            "holiday": holiday_name,
                            "revenue_boost": revenue,
                            "sales_boost": sales
                        })
                        
                except (ValueError, IndexError):
                    continue
        
        # Calculate monthly averages
        monthly_avg_revenue = {}
        monthly_avg_sales = {}
        for month in range(1, 13):
            if month in monthly_revenue:
                monthly_avg_revenue[month] = np.mean(monthly_revenue[month])
                monthly_avg_sales[month] = np.mean(monthly_sales[month])
            else:
                monthly_avg_revenue[month] = 0
                monthly_avg_sales[month] = 0
        
        # Find peak and low seasons
        peak_revenue_month = max(monthly_avg_revenue.items(), key=lambda x: x[1])
        low_revenue_month = min(monthly_avg_revenue.items(), key=lambda x: x[1])
        peak_sales_month = max(monthly_avg_sales.items(), key=lambda x: x[1])
        low_sales_month = min(monthly_avg_sales.items(), key=lambda x: x[1])
        
        analytics["monthly_stats"] = {
            "averages": {
                "revenue": monthly_avg_revenue,
                "sales": monthly_avg_sales
            },
            "peak_revenue": {"month": peak_revenue_month[0], "value": peak_revenue_month[1]},
            "low_revenue": {"month": low_revenue_month[0], "value": low_revenue_month[1]},
            "peak_sales": {"month": peak_sales_month[0], "value": peak_sales_month[1]},
            "low_sales": {"month": low_sales_month[0], "value": low_sales_month[1]},
            "seasonal_factor": peak_revenue_month[1] / abs(low_revenue_month[1]) if low_revenue_month[1] != 0 else 1,
            "volatility": np.std(list(monthly_avg_revenue.values()))
        }
        
        analytics["holiday_correlation"] = {
            "holiday_boosts": sorted(holiday_boosts, key=lambda x: x["revenue_boost"], reverse=True)[:5],
            "total_holiday_impact": sum(h["revenue_boost"] for h in holiday_boosts),
            "avg_holiday_boost": np.mean([h["revenue_boost"] for h in holiday_boosts]) if holiday_boosts else 0
        }
    
    # Weekly analytics
    if weekly_data:
        weekdays = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
        
        best_revenue_day = max(weekly_data, key=lambda x: x.get("weekly_revenue", 0))
        worst_revenue_day = min(weekly_data, key=lambda x: x.get("weekly_revenue", 0))
        best_sales_day = max(weekly_data, key=lambda x: x.get("weekly_sales", 0))
        worst_sales_day = min(weekly_data, key=lambda x: x.get("weekly_sales", 0))
        
        # Calculate weekly patterns
        revenue_variance = np.var([d.get("weekly_revenue", 0) for d in weekly_data])
        sales_variance = np.var([d.get("weekly_sales", 0) for d in weekly_data])
        
        analytics["weekly_stats"] = {
            "best_revenue_day": {
                "day": weekdays[weekly_data.index(best_revenue_day)],
                "value": best_revenue_day.get("weekly_revenue", 0)
            },
            "worst_revenue_day": {
                "day": weekdays[weekly_data.index(worst_revenue_day)],
                "value": worst_revenue_day.get("weekly_revenue", 0)
            },
            "best_sales_day": {
                "day": weekdays[weekly_data.index(best_sales_day)],
                "value": best_sales_day.get("weekly_sales", 0)
            },
            "worst_sales_day": {
                "day": weekdays[weekly_data.index(worst_sales_day)],
                "value": worst_sales_day.get("weekly_sales", 0)
            },
            "revenue_variance": revenue_variance,
            "sales_variance": sales_variance,
            "weekly_factor": best_revenue_day.get("weekly_revenue", 0) / abs(worst_revenue_day.get("weekly_revenue", 1)) if worst_revenue_day.get("weekly_revenue", 0) != 0 else 1
        }
    
    # Generate trends and YoY comparison (simulated for demo)
    current_year = datetime.now().year
    analytics["trends"] = {
        "yoy_growth": {
            "revenue": round(np.random.uniform(-10, 20), 1),  # Simulated YoY growth
            "sales": round(np.random.uniform(-5, 15), 1),
        },
        "trend_direction": "growth" if analytics.get("monthly_stats", {}).get("peak_revenue", {}).get("value", 0) > 5 else "decline",
        "seasonality_strength": "high" if analytics.get("monthly_stats", {}).get("seasonal_factor", 1) > 2 else "medium",
        "market_maturity": "developing"
    }
    
    # Simple forecasting
    if annual_data:
        next_month = (datetime.now().month % 12) + 1
        category_type = analytics["category_type"]
        pattern = CATEGORY_PATTERNS.get(category_type, CATEGORY_PATTERNS["default"])
        
        forecast_strength = "high" if next_month in pattern["peak_months"] else "low" if next_month in pattern["low_months"] else "medium"
        
        analytics["forecasting"] = {
            "next_month_forecast": forecast_strength,
            "predicted_growth": round(np.random.uniform(-5, 15), 1),
            "confidence": "medium",
            "recommended_actions": _generate_recommendations(analytics, category_path)
        }
    
    return analytics


def _generate_recommendations(analytics: Dict, category_path: str) -> List[str]:
    """Generate actionable recommendations based on seasonality data."""
    recommendations = []
    
    monthly_stats = analytics.get("monthly_stats", {})
    weekly_stats = analytics.get("weekly_stats", {})
    
    # Monthly recommendations
    if monthly_stats:
        peak_month = monthly_stats.get("peak_revenue", {}).get("month")
        low_month = monthly_stats.get("low_revenue", {}).get("month")
        current_month = datetime.now().month
        
        if peak_month and abs(current_month - peak_month) <= 1:
            recommendations.append(f"üìà –ü–∏–∫ —Å–µ–∑–æ–Ω–∞! –£–≤–µ–ª–∏—á—å—Ç–µ —Ä–µ–∫–ª–∞–º–Ω—ã–π –±—é–¥–∂–µ—Ç –Ω–∞ 30-50%")
        elif low_month and abs(current_month - low_month) <= 1:
            recommendations.append(f"üìâ –ù–∏–∑–∫–∏–π —Å–µ–∑–æ–Ω. –°–Ω–∏–∑—å—Ç–µ —Ü–µ–Ω—ã –Ω–∞ 10-15% –¥–ª—è —Å—Ç–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥–∞–∂")
    
    # Weekly recommendations
    if weekly_stats:
        best_day = weekly_stats.get("best_revenue_day", {}).get("day")
        if best_day:
            recommendations.append(f"üí° –õ—É—á—à–∏–π –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏: {best_day}. –ó–∞–ø—É—Å–∫–∞–π—Ç–µ –∞–∫—Ü–∏–∏ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å")
    
    # Holiday recommendations
    holiday_data = analytics.get("holiday_correlation", {})
    if holiday_data and holiday_data.get("avg_holiday_boost", 0) > 5:
        recommendations.append("üéâ –í—ã—Å–æ–∫–∏–π –æ—Ç–∫–ª–∏–∫ –Ω–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏. –ì–æ—Ç–æ–≤—å—Ç–µ —Å–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∑–∞—Ä–∞–Ω–µ–µ")
    
    # Trend-based recommendations
    trends = analytics.get("trends", {})
    if trends.get("yoy_growth", {}).get("revenue", 0) < 0:
        recommendations.append("‚ö†Ô∏è –°–Ω–∏–∂–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏ –≥–æ–¥ –∫ –≥–æ–¥—É. –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ü–µ–Ω–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
    
    return recommendations[:5]  # Top 5 recommendations


def _generate_heatmap_data(annual_data: List[Dict]) -> Dict[str, Any]:
    """Generate heat map data for visualization."""
    heatmap_data = {
        "months": list(range(1, 13)),
        "weekdays": list(range(1, 8)),
        "values": [[0 for _ in range(7)] for _ in range(12)]
    }
    
    # This would be populated with real heat map calculations
    # For now, generating simulated data
    for month in range(12):
        for weekday in range(7):
            heatmap_data["values"][month][weekday] = round(np.random.uniform(-10, 20), 1)
    
    return heatmap_data


async def get_seasonality_analysis(category_path: str):
    """Fetch both annual and weekly seasonality data concurrently with enhanced analytics."""
    # First attempt ‚Äî send the path as-is.
    annual_raw, weekly_raw = await asyncio.gather(
        get_seasonality_annual_data(category_path),
        get_seasonality_weekly_data(category_path),
    )

    # If both datasets are empty, try URL-encoded category (for cases when MPSTATS
    # expects %2F-encoded slashes).
    if not annual_raw and not weekly_raw:
        from urllib.parse import quote

        encoded_path = quote(category_path, safe="")
        if encoded_path != category_path:
            logger.info("Seasonality fallback: retrying with encoded path %s", encoded_path)
            annual_raw, weekly_raw = await asyncio.gather(
                get_seasonality_annual_data(encoded_path),
                get_seasonality_weekly_data(encoded_path),
            )

    # Debug logging: show what we received
    logger.debug("Raw annual response: %s", annual_raw)
    logger.debug("Raw weekly response: %s", weekly_raw)

    def _to_list(raw):
        """MPSTATS –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –º–µ—Ç–æ–¥–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç { data: [...] }. –≠—Ç–æ—Ç —Ö–µ–ª–ø–µ—Ä –ø—Ä–∏–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ —Å–ø–∏—Å–∫—É.
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äì –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –º–æ–≥ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞—Ç—å."""
        if raw is None:
            return []

        # –ü—Ä—è–º–æ–π —Å–ø–∏—Å–æ–∫
        if isinstance(raw, list):
            return raw

        # –ü–æ–ø—ã—Ç–∫–∞ –¥–æ—Å—Ç–∞—Ç—å –ø–æ–ª–µ "data"
        if isinstance(raw, dict):
            if "data" in raw and isinstance(raw["data"], list):
                return raw["data"]
            # –ò–Ω–æ–≥–¥–∞ MPSTATS –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å payload –≤ –ø–æ–ª–µ "result"
            if "result" in raw and isinstance(raw["result"], list):
                return raw["result"]

        # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äì –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å, —É–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–π –≤ —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ñ—Ä–æ–Ω—Ç
        return [] if raw == {} else [raw]

    annual = _to_list(annual_raw)
    weekly = _to_list(weekly_raw)

    # Build textual summary similar to bot
    def _build_summary(annual, weekly):
        summary_parts = [f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category_path}\n"]

        if not annual and not weekly:
            summary_parts.append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.")
            return "\n".join(summary_parts)

        # Weekly insights
        if weekly:
            weekdays = [
                "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫","–í—Ç–æ—Ä–Ω–∏–∫","–°—Ä–µ–¥–∞","–ß–µ—Ç–≤–µ—Ä–≥","–ü—è—Ç–Ω–∏—Ü–∞","–°—É–±–±–æ—Ç–∞","–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"
            ]
            best_rev = max(weekly, key=lambda x: x.get("weekly_revenue", 0))
            worst_rev = min(weekly, key=lambda x: x.get("weekly_revenue", 0))
            best_sales = max(weekly, key=lambda x: x.get("weekly_sales", 0))
            worst_sales = min(weekly, key=lambda x: x.get("weekly_sales", 0))

            idx = weekly.index(best_rev)
            summary_parts.append(f"üí∞ –õ—É—á—à–∞—è –≤—ã—Ä—É—á–∫–∞: *{weekdays[idx]}* ({best_rev.get('weekly_revenue',0):+.1f}%)")
            idx = weekly.index(worst_rev)
            summary_parts.append(f"üìâ –•—É–¥—à–∞—è –≤—ã—Ä—É—á–∫–∞: *{weekdays[idx]}* ({worst_rev.get('weekly_revenue',0):+.1f}%)")

            idx = weekly.index(best_sales)
            summary_parts.append(f"üõí –õ—É—á—à–∏–µ –ø—Ä–æ–¥–∞–∂–∏: *{weekdays[idx]}* ({best_sales.get('weekly_sales',0):+.1f}%)")
            idx = weekly.index(worst_sales)
            summary_parts.append(f"üö´ –•—É–¥—à–∏–µ –ø—Ä–æ–¥–∞–∂–∏: *{weekdays[idx]}* ({worst_sales.get('weekly_sales',0):+.1f}%)*")

            # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –Ω–µ–¥–µ–ª–µ
            avg_rev = sum(x.get("weekly_revenue",0) for x in weekly)/len(weekly)
            avg_sales = sum(x.get("weekly_sales",0) for x in weekly)/len(weekly)
            summary_parts.append(f"\nüîé *–°—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏ –ø–æ –Ω–µ–¥–µ–ª–µ*: {avg_rev:+.1f}%")
            summary_parts.append(f"üîé *–°—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ –ø–æ –Ω–µ–¥–µ–ª–µ*: {avg_sales:+.1f}%")

        if annual:
            filtr = [x for x in annual if x.get("noyeardate")]
            if filtr:
                top = sorted(filtr, key=lambda x: x.get("season_revenue",0), reverse=True)[:3]
                bot = sorted(filtr, key=lambda x: x.get("season_revenue",0))[:3]
                summary_parts.append("\nüèÜ *–¢–æ–ø-3 –¥–∞—Ç—ã –ø–æ –≤—ã—Ä—É—á–∫–µ*: ")
                for d in top:
                    summary_parts.append(f"‚Ä¢ {d.get('noyeardate')} : {d.get('season_revenue',0):+.1f}%")
                summary_parts.append("\nüíÄ *–•—É–¥—à–∏–µ-3 –¥–∞—Ç—ã –ø–æ –≤—ã—Ä—É—á–∫–µ*:")
                for d in bot:
                    summary_parts.append(f"‚Ä¢ {d.get('noyeardate')} : {d.get('season_revenue',0):+.1f}%")

                # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–¥—É
                rev_list = [x.get("season_revenue",0) for x in filtr]
                sales_list = [x.get("season_sales",0) for x in filtr]
                mean_rev = sum(rev_list)/len(rev_list)
                mean_sales = sum(sales_list)/len(sales_list)
                pos_days = sum(1 for r in rev_list if r>0)
                neg_days = len(rev_list)-pos_days
                summary_parts.append("\nüìä *–ò—Ç–æ–≥–æ –ø–æ –≥–æ–¥—É*:")
                summary_parts.append(f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏: {mean_rev:+.1f}%")
                summary_parts.append(f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂: {mean_sales:+.1f}%")
                summary_parts.append(f"‚Ä¢ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–Ω–µ–π: {pos_days} | –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö: {neg_days}")

        return "\n".join(summary_parts)

    # Generate enhanced analytics
    enhanced_analytics = _generate_enhanced_analytics(annual, weekly, category_path)
    heatmap_data = _generate_heatmap_data(annual)
    summary_text = _build_summary(annual, weekly)

    return {
        "annualData": annual,
        "weeklyData": weekly,
        "category": category_path,
        "summary": summary_text,
        "analytics": enhanced_analytics,
        "heatmapData": heatmap_data,
        "lastUpdated": datetime.now().isoformat()
    } 