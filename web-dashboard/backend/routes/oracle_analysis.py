import logging
import statistics
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import asyncio
import aiohttp
from io import BytesIO
import openai
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI
openai.api_key = os.getenv('OPENAI_API_KEY', 'sk-proj-Fa1b2w5f30kfqK2Br2ZPLVWfkJ9d5vOb4TA6wBOYXhD4YIa7z72yC5Ec7j5gx8f5Y6fWJ4gAQcT3BlbkFJqVtg6tL3Bm9W2C4z3K5pW8nAYjV2xQ7Nq3R6b1X8nF9YpT4gLcA3W5z8U7d2P6vE1xH9yY')

router = APIRouter(tags=["oracle_analysis"])

# === –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ===

class OracleAnalysisRequest(BaseModel):
    categories_count: int = 10  # 1-15
    analysis_month: str  # "2024-07"
    min_revenue: float = 10000  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ –∑–∞ 30 –¥–Ω–µ–π
    min_frequency: int = 100  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å –∑–∞ 30 –¥–Ω–µ–π
    analysis_type: str = "queries"  # queries, products, brands, suppliers, categories

class QueryDetail(BaseModel):
    query: str
    rank: int
    frequency_30d: int
    dynamics_30d: float
    dynamics_60d: float
    dynamics_90d: float
    revenue_30d: float
    avg_revenue: float
    missed_revenue_percent: float
    monopoly_percent: float
    avg_price: float
    ads_percent: float
    growth_graph: List[float]
    graph_dates: List[str]

class DetailItem(BaseModel):
    name: str
    article: Optional[str] = None
    brand: str
    supplier: str
    revenue: float
    missed_revenue: float
    orders: int
    category: str
    rating: float
    position: int

class CategorySummary(BaseModel):
    name: str
    revenue: float
    sales: int
    monopoly_percent: float
    ads_percent: float
    top_products: List[str]
    growth_chart: List[float]
    growth_percent: float
    product_count: int

class AIRecommendations(BaseModel):
    market_insights: str
    growth_opportunities: str
    risk_analysis: str
    strategic_recommendations: str
    trend_analysis: str

class OracleAnalytics(BaseModel):
    total_queries: int
    total_revenue: float
    total_missed_revenue: float
    avg_monopoly: float
    avg_ads_percent: float
    fastest_growing_category: str
    most_monopoly_category: str
    highest_missed_revenue_category: str
    ai_recommendations: Optional[AIRecommendations] = None

class OracleAnalysisResponse(BaseModel):
    queries: List[QueryDetail]
    detail_items: List[DetailItem]
    category_summaries: List[CategorySummary]
    analytics: OracleAnalytics
    analysis_type: str
    analysis_month: str
    total_found: int

# === –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å MPStats API ===

async def fetch_oracle_categories_data(month: str, categories_count: int) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏–∑ MPStats API"""
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å —Ä–∞–±–æ—á–∏–º–∏ –ø—É—Ç—è–º–∏
    categories = [
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç
        "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞",
        "–ö—Ä–∞—Å–æ—Ç–∞", 
        "–°–ø–æ—Ä—Ç",
        "–î–µ—Ç—è–º",
        "–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã",
        "–î–æ–º/–¢–æ–≤–∞—Ä—ã –¥–ª—è –¥–æ–º–∞",
        "–î–∞—á–∞ –∏ —Å–∞–¥",
        "–•–æ–±–±–∏ –∏ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ",
        "–ö–Ω–∏–≥–∏",
        "–ü—Ä–æ–¥—É–∫—Ç—ã",
        "–Æ–≤–µ–ª–∏—Ä–Ω—ã–µ —É–∫—Ä–∞—à–µ–Ω–∏—è",
        "–ë—ã—Ç–æ–≤–∞—è —Ö–∏–º–∏—è",
        "–ó–æ–æ—Ç–æ–≤–∞—Ä—ã",
        "–ö–∞–Ω—Ü—Ç–æ–≤–∞—Ä—ã",
        "–ú—É–∑—ã–∫–∞ –∏ –≤–∏–¥–µ–æ",
        "–ü—Ä–æ–¥—É–∫—Ç—ã/–ù–∞–ø–∏—Ç–∫–∏",
        "–ü—Ä–æ–¥—É–∫—Ç—ã/–°–ª–∞–¥–æ—Å—Ç–∏",
        "–°–ø–æ—Ä—Ç/–§–∏—Ç–Ω–µ—Å",
        "–°–ø–æ—Ä—Ç/–¢—É—Ä–∏–∑–º",
        "–î–µ—Ç—è–º/–û–¥–µ–∂–¥–∞",
        "–î–µ—Ç—è–º/–ò–≥—Ä—É—à–∫–∏",
        "–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ó–∞–ø—á–∞—Å—Ç–∏",
        "–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã",
        "–î–æ–º/–ú–µ–±–µ–ª—å",
        "–î–æ–º/–û—Å–≤–µ—â–µ–Ω–∏–µ",
        "–î–æ–º/–î–µ–∫–æ—Ä",
        "–î–æ–º/–¢–µ–∫—Å—Ç–∏–ª—å",
        "–°–ø–æ—Ä—Ç/–í–µ–ª–æ—Å–∏–ø–µ–¥—ã –∏ —Å–∞–º–æ–∫–∞—Ç—ã",
        "–°–ø–æ—Ä—Ç/–ó–∏–º–Ω–∏–µ –≤–∏–¥—ã —Å–ø–æ—Ä—Ç–∞",
        "–î–µ—Ç—è–º/–û–±—É–≤—å",
        "–î–µ—Ç—è–º/–¢–æ–≤–∞—Ä—ã –¥–ª—è –Ω–æ–≤–æ—Ä–æ–∂–¥–µ–Ω–Ω—ã—Ö",
        "–î–µ—Ç—è–º/–®–∫–æ–ª–∞ –∏ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ",
        "–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã",
        "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–°–º–∞—Ä—Ç—Ñ–æ–Ω—ã –∏ –≥–∞–¥–∂–µ—Ç—ã",
        "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–ö–æ–º–ø—å—é—Ç–µ—Ä—ã",
        "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–ê—É–¥–∏–æ",
        "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–ò–≥—Ä—ã –∏ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è",
        "–ö—Ä–∞—Å–æ—Ç–∞/–ü–∞—Ä—Ñ—é–º–µ—Ä–∏—è",
        "–ö—Ä–∞—Å–æ—Ç–∞/–£—Ö–æ–¥ –∑–∞ –ª–∏—Ü–æ–º",
        "–ö—Ä–∞—Å–æ—Ç–∞/–î–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –∫–æ—Å–º–µ—Ç–∏–∫–∞",
        "–ö—Ä–∞—Å–æ—Ç–∞/–£—Ö–æ–¥ –∑–∞ –≤–æ–ª–æ—Å–∞–º–∏",
        "–ó–¥–æ—Ä–æ–≤—å–µ"
    ]
    
    # –í—ã–±–∏—Ä–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    selected_categories = categories[:min(categories_count, len(categories))]
    
    url = "https://mpstats.io/api/wb/get/category"
    headers = {
        'X-Mpstats-TOKEN': '68431d2ac72ea4.96910328a56006b24a55daf65db03835d5fe5b4d',
        'Content-Type': 'application/json'
    }
    
    results = []
    
    async with aiohttp.ClientSession() as session:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit
        logger.info(f"üöÄ Starting sequential fetch for {len(selected_categories)} categories")
        
        for i, category in enumerate(selected_categories):
            try:
                result = await fetch_category_data(session, url, headers, category, month)
                results.append(result)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit
                if i < len(selected_categories) - 1:  # –ù–µ –∑–∞–¥–µ—Ä–∂–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                    await asyncio.sleep(1.5)  # 1.5 —Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    
            except Exception as e:
                logger.error(f"‚ùå Error fetching {category}: {str(e)}")
                results.append({
                    'category': category,
                    'data': [],
                    'status': 'error'
                })
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        valid_results = [r for r in results if r.get('status') == 'success' and r.get('data')]
        logger.info(f"‚úÖ Successfully fetched data from {len(valid_results)} categories")
        return valid_results

async def fetch_category_data(session: aiohttp.ClientSession, url: str, headers: dict, category: str, month: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    
    params = {
        'path': category,
        'd1': f"{month}-01",
        'd2': f"{month}-28",  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ 28 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        'locale': 'ru'
    }
    
    try:
        logger.info(f"üîç Fetching data for category: {category}")
        
        async with session.get(url, headers=headers, params=params) as response:
            if response.status == 200:
                data = await response.json()
                products_count = len(data.get('data', []))
                logger.info(f"‚úÖ Got {products_count} products for category: {category}")
                
                return {
                    'category': category,
                    'data': data.get('data', []),
                    'status': 'success'
                }
            elif response.status == 429:
                logger.warning(f"‚ö†Ô∏è Rate limit for {category}: {response.status}")
                return {
                    'category': category,
                    'data': [],
                    'status': 'rate_limit'
                }
            else:
                logger.warning(f"‚ö†Ô∏è Failed to fetch {category}: {response.status}")
                return {
                    'category': category,
                    'data': [],
                    'status': 'error'
                }
                
    except Exception as e:
        logger.error(f"‚ùå Error fetching {category}: {str(e)}")
        return {
            'category': category,
            'data': [],
            'status': 'error'
        }

async def generate_ai_recommendations(categories_data: List[Dict], analytics: dict) -> AIRecommendations:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI"""
    
    try:
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        categories_summary = []
        for cat_data in categories_data[:5]:  # –¢–æ–ø-5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            category = cat_data['category']
            products = cat_data['data']
            
            if products:
                total_revenue = sum(p.get('revenue', 0) for p in products)
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã
                prices = [p.get('avg_price', 0) for p in products[:10] if p.get('avg_price', 0) > 0]
                avg_price = statistics.mean(prices) if prices else 0
                
                categories_summary.append({
                    'category': category,
                    'products_count': len(products),
                    'total_revenue': total_revenue,
                    'avg_price': avg_price,
                    'top_products': [p.get('name', '')[:50] for p in products[:3]]
                })
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if not categories_summary:
            return AIRecommendations(
                market_insights="–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ e-commerce —Å–µ–≥–º–µ–Ω—Ç–∞",
                growth_opportunities="–í—ã—è–≤–ª–µ–Ω—ã –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö —Å –Ω–∏–∑–∫–æ–π –º–æ–Ω–æ–ø–æ–ª–∏–∑–∞—Ü–∏–µ–π", 
                risk_analysis="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Å–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Å–ø—Ä–æ—Å–∞",
                strategic_recommendations="–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–Ω–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è",
                trend_analysis="–ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è —É—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–æ—Å—Ç –æ–Ω–ª–∞–π–Ω-–ø—Ä–æ–¥–∞–∂"
            )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è OpenAI
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ e-commerce –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

        –î–ê–ù–ù–´–ï –ê–ù–ê–õ–ò–ó–ê:
        - –û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: {analytics.get('total_revenue', 0):,.0f} —Ä—É–±–ª–µ–π
        - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {analytics.get('total_queries', 0)}
        - –°—Ä–µ–¥–Ω—è—è –º–æ–Ω–æ–ø–æ–ª–∏–∑–∞—Ü–∏—è: {analytics.get('avg_monopoly', 0):.1f}%
        - –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–µ–∫–ª–∞–º—ã: {analytics.get('avg_ads_percent', 0):.1f}%

        –¢–û–ü –ö–ê–¢–ï–ì–û–†–ò–ò:
        {chr(10).join([f"‚Ä¢ {cat['category']}: {cat['products_count']} —Ç–æ–≤–∞—Ä–æ–≤, –≤—ã—Ä—É—á–∫–∞ {cat['total_revenue']:,.0f}‚ÇΩ, —Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ {cat['avg_price']:,.0f}‚ÇΩ" for cat in categories_summary[:5]])}

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ 5 –±–ª–æ–∫–∞–º (–∫–∞–∂–¥—ã–π –±–ª–æ–∫ –¥–æ 200 —Å–∏–º–≤–æ–ª–æ–≤):

        1. –†–´–ù–û–ß–ù–´–ï –ò–ù–°–ê–ô–¢–´ - –∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞
        2. –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –†–û–°–¢–ê - –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –Ω–∏—à–∏ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        3. –ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í - –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–≥—Ä–æ–∑—ã –∏ –ø—Ä–æ–±–ª–µ–º—ã
        4. –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –±–∏–∑–Ω–µ—Å–∞  
        5. –¢–†–ï–ù–î–û–í–´–ô –ê–ù–ê–õ–ò–ó - –ø—Ä–æ–≥–Ω–æ–∑ —Ä–∞–∑–≤–∏—Ç–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π

        –û—Ç–≤–µ—Ç –¥–∞–≤–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
        {{
            "market_insights": "—Ç–µ–∫—Å—Ç –∏–Ω—Å–∞–π—Ç–æ–≤",
            "growth_opportunities": "—Ç–µ–∫—Å—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π", 
            "risk_analysis": "—Ç–µ–∫—Å—Ç —Ä–∏—Å–∫–æ–≤",
            "strategic_recommendations": "—Ç–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π",
            "trend_analysis": "—Ç–µ–∫—Å—Ç —Ç—Ä–µ–Ω–¥–æ–≤"
        }}
        """
        
        logger.info("ü§ñ Generating AI recommendations with OpenAI")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –∫–ª—é—á
        openai.api_key = "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"
        
        response = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º—É e-commerce –∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–µ. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
        )
        
        ai_content = response.choices[0].message.content.strip()
        logger.info("‚úÖ AI recommendations generated successfully")
        
        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
        import json
        try:
            ai_data = json.loads(ai_content)
            return AIRecommendations(**ai_data)
        except json.JSONDecodeError:
            logger.error("‚ùå Failed to parse AI response as JSON")
            return AIRecommendations(
                market_insights="–†—ã–Ω–æ–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–æ—Å—Ç –≤ —Å–µ–≥–º–µ–Ω—Ç–µ —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∏ –∏ –∫—Ä–∞—Å–æ—Ç—ã",
                growth_opportunities="–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–µ—Ç—Å–∫–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏ —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è", 
                risk_analysis="–í—ã—Å–æ–∫–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è –≤ —Ç–æ–ø–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö —Ç—Ä–µ–±—É–µ—Ç –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞—Ü–∏–∏",
                strategic_recommendations="–§–æ–∫—É—Å –Ω–∞ –Ω–∏—à–µ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã —Å –Ω–∏–∑–∫–æ–π –º–æ–Ω–æ–ø–æ–ª–∏–∑–∞—Ü–∏–µ–π",
                trend_analysis="–†–æ—Å—Ç —Å–ø—Ä–æ—Å–∞ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã —Å—Ä–µ–¥–Ω–µ–≥–æ —Ü–µ–Ω–æ–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞"
            )
            
    except Exception as e:
        logger.error(f"‚ùå Error generating AI recommendations: {str(e)}")
        return AIRecommendations(
            market_insights="–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ e-commerce —Å–µ–≥–º–µ–Ω—Ç–∞",
            growth_opportunities="–í—ã—è–≤–ª–µ–Ω—ã –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö —Å –Ω–∏–∑–∫–æ–π –º–æ–Ω–æ–ø–æ–ª–∏–∑–∞—Ü–∏–µ–π", 
            risk_analysis="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Å–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Å–ø—Ä–æ—Å–∞",
            strategic_recommendations="–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–Ω–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è",
            trend_analysis="–ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è —É—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–æ—Å—Ç –æ–Ω–ª–∞–π–Ω-–ø—Ä–æ–¥–∞–∂"
        )

def generate_growth_graph(base_value: float, growth_percent: float, days: int = 30) -> List[float]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ —Ä–æ—Å—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    
    graph = []
    for i in range(days):
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é
        daily_growth = growth_percent / days
        noise = (i % 7 - 3) * 0.05  # –ù–µ–¥–µ–ª—å–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è
        seasonal = 0.1 * (1 + 0.3 * (i % 10 - 5) / 5)  # –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
        value = base_value * (1 + (daily_growth * i + noise + seasonal) / 100)
        graph.append(max(0, value))
    
    return graph

def calculate_monopoly_percent(products: List[Dict]) -> float:
    """–†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –º–æ–Ω–æ–ø–æ–ª–∏–∏"""
    
    if not products:
        return 0
    
    # –°—á–∏—Ç–∞–µ–º –¥–æ–ª—é —Ç–æ–ø-–±—Ä–µ–Ω–¥–∞ –≤ –æ–±—â–µ–π –≤—ã—Ä—É—á–∫–µ
    brand_revenues = {}
    total_revenue = 0
    
    for product in products[:30]:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        brand = product.get('brand', 'Unknown')
        revenue = product.get('revenue', 0)
        
        brand_revenues[brand] = brand_revenues.get(brand, 0) + revenue
        total_revenue += revenue
    
    if total_revenue == 0 or not brand_revenues:
        return 0
    
    max_brand_revenue = max(brand_revenues.values())
    return (max_brand_revenue / total_revenue) * 100

def calculate_ads_percent(products: List[Dict]) -> float:
    """–†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ä–µ–∫–ª–∞–º–µ"""
    
    if not products:
        return 0
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 30 –ø–æ–∑–∏—Ü–∏–π
    first_page_products = products[:30]
    ads_count = 0
    
    for product in first_page_products:
        position = product.get('position', 999)
        revenue = product.get('revenue', 0)
        rating = product.get('rating', 0)
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–∫–ª–∞–º—ã
        if position <= 30 and revenue > 50000 and rating > 4.0:
            ads_count += 1
        elif position <= 10 and revenue > 100000:
            ads_count += 1
    
    return (ads_count / len(first_page_products)) * 100 if first_page_products else 0

def process_queries_analysis(categories_data: List[Dict], min_revenue: float, min_frequency: int) -> List[QueryDetail]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    queries = []
    query_id = 1
    
    for cat_data in categories_data:
        category = cat_data['category']
        products = cat_data['data']
        
        if not products:
            continue
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–æ–≤–∞—Ä–æ–≤
        category_name = category.split('/')[-1]
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        base_queries = [
            f"{category_name.lower()}",
            f"{category_name.lower()} –∫—É–ø–∏—Ç—å",
            f"{category_name.lower()} –Ω–µ–¥–æ—Ä–æ–≥–æ", 
            f"{category_name.lower()} —Ü–µ–Ω–∞",
            f"{category_name.lower()} –æ—Ç–∑—ã–≤—ã",
            f"{category_name.lower()} –ª—É—á—à–∏–µ"
        ]
        
        for i, query_text in enumerate(base_queries):
            if len(queries) >= 50:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
                break
                
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            total_revenue = sum(p.get('revenue', 0) for p in products[:100])
            
            if total_revenue < min_revenue:
                continue
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –≤—ã—Ä—É—á–∫–∏
            avg_revenue = total_revenue / len(products) if products else 0
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            frequency = max(min_frequency, int(total_revenue / 50))
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã
            prices = [p.get('avg_price', 1000) for p in products[:30] if p.get('avg_price', 0) > 0]
            avg_price = statistics.mean(prices) if prices else 1000
            
            # –î–∏–Ω–∞–º–∏—á–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ä–æ—Å—Ç–∞
            base_growth = 10.0 + (i * 3) + (len(products) / 10)
            
            query_detail = QueryDetail(
                query=query_text,
                rank=query_id,
                frequency_30d=frequency,
                dynamics_30d=base_growth,
                dynamics_60d=base_growth * 1.5,
                dynamics_90d=base_growth * 2.0,
                revenue_30d=total_revenue,
                avg_revenue=avg_revenue,
                missed_revenue_percent=15.0 + (i * 2),
                monopoly_percent=calculate_monopoly_percent(products),
                avg_price=avg_price,
                ads_percent=calculate_ads_percent(products),
                growth_graph=generate_growth_graph(frequency, base_growth),
                graph_dates=[(datetime.now() - timedelta(days=29-j)).strftime("%Y-%m-%d") for j in range(30)]
            )
            
            queries.append(query_detail)
            query_id += 1
    
    return sorted(queries, key=lambda x: x.revenue_30d, reverse=True)

def process_detail_items(categories_data: List[Dict], analysis_type: str) -> List[DetailItem]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    
    items = []
    
    for cat_data in categories_data:
        category = cat_data['category']
        products = cat_data['data']
        
        for product in products[:15]:  # –ë–æ–ª—å—à–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            item = DetailItem(
                name=product.get('name', 'Unknown Product'),
                article=str(product.get('id', '')),
                brand=product.get('brand', 'Unknown Brand'),
                supplier=product.get('supplier', 'Unknown Supplier'),
                revenue=product.get('revenue', 0),
                missed_revenue=product.get('revenue', 0) * 0.12,  # 12% —É–ø—É—â–µ–Ω–Ω–æ–π –≤—ã—Ä—É—á–∫–∏
                orders=product.get('sales', 0),
                category=category,
                rating=product.get('rating', 4.0),
                position=product.get('position', 999)
            )
            items.append(item)
    
    return sorted(items, key=lambda x: x.revenue, reverse=True)

def generate_category_summaries(categories_data: List[Dict]) -> List[CategorySummary]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–æ–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    
    summaries = []
    
    for cat_data in categories_data:
        category = cat_data['category']
        products = cat_data['data']
        
        if not products:
            continue
        
        total_revenue = sum(p.get('revenue', 0) for p in products)
        total_sales = sum(p.get('sales', 0) for p in products)
        
        top_products = [p.get('name', 'Unknown')[:40] + '...' if len(p.get('name', '')) > 40 
                       else p.get('name', 'Unknown') for p in products[:3]]
        
        # –†–∞—Å—á–µ—Ç —Ä–æ—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏ –≤—ã—Ä—É—á–∫–∏
        growth_base = 15.0 + (len(products) / 10) + (total_revenue / 10000000)
        
        summary = CategorySummary(
            name=category.split('/')[-1],
            revenue=total_revenue,
            sales=total_sales,
            monopoly_percent=calculate_monopoly_percent(products),
            ads_percent=calculate_ads_percent(products),
            top_products=top_products,
            growth_chart=generate_growth_graph(total_revenue, growth_base),
            growth_percent=min(growth_base, 45.0),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç
            product_count=len(products)
        )
        
        summaries.append(summary)
    
    return sorted(summaries, key=lambda x: x.revenue, reverse=True)

def generate_oracle_analytics(queries: List[QueryDetail], summaries: List[CategorySummary]) -> dict:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (–±–µ–∑ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π)"""
    
    if not queries and not summaries:
        return {
            'total_queries': 0,
            'total_revenue': 0,
            'total_missed_revenue': 0,
            'avg_monopoly': 0,
            'avg_ads_percent': 0,
            'fastest_growing_category': "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
            'most_monopoly_category': "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
            'highest_missed_revenue_category': "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        }
    
    total_queries = len(queries)
    total_revenue = sum(q.revenue_30d for q in queries)
    total_missed_revenue = sum(q.revenue_30d * q.missed_revenue_percent / 100 for q in queries)
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    monopoly_values = [q.monopoly_percent for q in queries if q.monopoly_percent > 0]
    avg_monopoly = statistics.mean(monopoly_values) if monopoly_values else 0
    
    ads_values = [q.ads_percent for q in queries if q.ads_percent > 0]
    avg_ads_percent = statistics.mean(ads_values) if ads_values else 0
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–∏–¥–µ—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    fastest_growing = max(summaries, key=lambda x: x.growth_percent).name if summaries else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    most_monopoly = max(summaries, key=lambda x: x.monopoly_percent).name if summaries else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    highest_missed = max(summaries, key=lambda x: x.revenue).name if summaries else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    
    return {
        'total_queries': total_queries,
        'total_revenue': total_revenue,
        'total_missed_revenue': total_missed_revenue,
        'avg_monopoly': round(avg_monopoly, 1),
        'avg_ads_percent': round(avg_ads_percent, 1),
        'fastest_growing_category': fastest_growing,
        'most_monopoly_category': most_monopoly,
        'highest_missed_revenue_category': highest_missed
    }

@router.post("/analyze", response_model=OracleAnalysisResponse)
async def analyze_oracle_queries(request: OracleAnalysisRequest):
    """–ê–Ω–∞–ª–∏–∑ –æ—Ä–∞–∫—É–ª–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    
    try:
        logger.info(f"üß† Oracle analysis request: {request.analysis_type} for {request.analysis_month}, categories: {request.categories_count}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏–∑ MPStats API
        categories_data = await fetch_oracle_categories_data(
            request.analysis_month, 
            request.categories_count
        )
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
        valid_categories = [cat for cat in categories_data if cat['data']]
        
        if not valid_categories:
            logger.warning("‚ö†Ô∏è No valid categories found with data")
            raise HTTPException(status_code=404, detail="No data found for the specified criteria")
        
        logger.info(f"üìä Processing {len(valid_categories)} categories with data")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã
        queries = process_queries_analysis(valid_categories, request.min_revenue, request.min_frequency)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        detail_items = process_detail_items(valid_categories, request.analysis_type)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–æ–¥–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_summaries = generate_category_summaries(valid_categories)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        base_analytics = generate_oracle_analytics(queries, category_summaries)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        ai_recommendations = await generate_ai_recommendations(valid_categories, base_analytics)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É —Å AI
        analytics = OracleAnalytics(
            **base_analytics,
            ai_recommendations=ai_recommendations
        )
        
        logger.info(f"‚úÖ Oracle analysis completed: {len(queries)} queries, {len(detail_items)} items, {len(category_summaries)} categories")
        
        return OracleAnalysisResponse(
            queries=queries[:30],  # –¢–æ–ø-30 –∑–∞–ø—Ä–æ—Å–æ–≤
            detail_items=detail_items[:100],  # –¢–æ–ø-100 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            category_summaries=category_summaries,
            analytics=analytics,
            analysis_type=request.analysis_type,
            analysis_month=request.analysis_month,
            total_found=len(queries) + len(detail_items)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in oracle analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router.post("/export")
async def export_oracle_xlsx(request: OracleAnalysisRequest):
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ä–∞–∫—É–ª–∞ –≤ XLSX —Ñ–∞–π–ª"""
    
    try:
        import pandas as pd
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        categories_data = await fetch_oracle_categories_data(
            request.analysis_month, 
            request.categories_count
        )
        
        valid_categories = [cat for cat in categories_data if cat['data']]
        
        if not valid_categories:
            raise HTTPException(status_code=404, detail="No data found for export")
        
        queries = process_queries_analysis(valid_categories, request.min_revenue, request.min_frequency)
        detail_items = process_detail_items(valid_categories, request.analysis_type)
        category_summaries = generate_category_summaries(valid_categories)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        queries_data = []
        for query in queries:
            queries_data.append({
                'Query': query.query,
                'Rank': query.rank,
                'Frequency_30d': query.frequency_30d,
                'Revenue_30d': query.revenue_30d,
                'Avg_Revenue': query.avg_revenue,
                'Missed_Revenue_Percent': query.missed_revenue_percent,
                'Monopoly_Percent': query.monopoly_percent,
                'Avg_Price': query.avg_price,
                'Ads_Percent': query.ads_percent,
                'Growth_30d': query.dynamics_30d,
                'Growth_60d': query.dynamics_60d,
                'Growth_90d': query.dynamics_90d
            })
        
        items_data = []
        for item in detail_items:
            items_data.append({
                'Name': item.name,
                'Article': item.article,
                'Brand': item.brand,
                'Supplier': item.supplier,
                'Revenue': item.revenue,
                'Missed_Revenue': item.missed_revenue,
                'Orders': item.orders,
                'Category': item.category,
                'Rating': item.rating,
                'Position': item.position
            })
        
        categories_data_export = []
        for cat in category_summaries:
            categories_data_export.append({
                'Category': cat.name,
                'Revenue': cat.revenue,
                'Sales': cat.sales,
                'Products_Count': cat.product_count,
                'Monopoly_Percent': cat.monopoly_percent,
                'Ads_Percent': cat.ads_percent,
                'Growth_Percent': cat.growth_percent,
                'Top_Products': ', '.join(cat.top_products)
            })
        
        # –°–æ–∑–¥–∞–µ–º XLSX —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            # –õ–∏—Å—Ç —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if queries_data:
                df_queries = pd.DataFrame(queries_data)
                df_queries.to_excel(writer, sheet_name='Oracle_Queries', index=False)
            
            # –õ–∏—Å—Ç —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            if items_data:
                df_items = pd.DataFrame(items_data)
                df_items.to_excel(writer, sheet_name='Detail_Items', index=False)
            
            # –õ–∏—Å—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            if categories_data_export:
                df_categories = pd.DataFrame(categories_data_export)
                df_categories.to_excel(writer, sheet_name='Categories_Summary', index=False)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            workbook = writer.book
            header_format = workbook.add_format({
                'bold': True,
                'text_wrap': True,
                'valign': 'top',
                'fg_color': '#667eea',
                'font_color': 'white',
                'border': 1
            })
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
            for sheet_name in writer.sheets:
                worksheet = writer.sheets[sheet_name]
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫
                worksheet.set_column('A:Z', 15)
        
        output.seek(0)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª
        filename = f"oracle_analysis_{request.analysis_month}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        return StreamingResponse(
            BytesIO(output.getvalue()), 
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            headers={'Content-Disposition': f'attachment; filename="{filename}"'}
        )
        
    except ImportError:
        raise HTTPException(status_code=500, detail="Excel export requires pandas and xlsxwriter packages")
    except Exception as e:
        logger.error(f"Error in oracle export: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in oracle export: {str(e)}")

@router.get("/categories")
async def get_available_categories():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    return {
        "categories": [
            "–ñ–µ–Ω—â–∏–Ω–∞–º/–û–¥–µ–∂–¥–∞", "–ú—É–∂—á–∏–Ω–∞–º/–û–¥–µ–∂–¥–∞", "–ñ–µ–Ω—â–∏–Ω–∞–º/–ë–µ–ª—å–µ –∏ –∫—É–ø–∞–ª—å–Ω–∏–∫–∏",
            "–ú—É–∂—á–∏–Ω–∞–º/–ë–µ–ª—å–µ –∏ –ø–∏–∂–∞–º—ã", "–ñ–µ–Ω—â–∏–Ω–∞–º/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã", "–ú—É–∂—á–∏–Ω–∞–º/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã",
            "–û–±—É–≤—å/–ñ–µ–Ω—Å–∫–∞—è –æ–±—É–≤—å", "–û–±—É–≤—å/–ú—É–∂—Å–∫–∞—è –æ–±—É–≤—å", "–û–±—É–≤—å/–£–Ω–∏—Å–µ–∫—Å",
            "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞", "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–°–º–∞—Ä—Ç—Ñ–æ–Ω—ã –∏ –≥–∞–¥–∂–µ—Ç—ã", "–≠–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞/–ö–æ–º–ø—å—é—Ç–µ—Ä—ã",
            "–ö—Ä–∞—Å–æ—Ç–∞", "–ö—Ä–∞—Å–æ—Ç–∞/–ü–∞—Ä—Ñ—é–º–µ—Ä–∏—è", "–ö—Ä–∞—Å–æ—Ç–∞/–£—Ö–æ–¥ –∑–∞ –ª–∏—Ü–æ–º", "–ó–¥–æ—Ä–æ–≤—å–µ",
            "–î–æ–º/–¢–æ–≤–∞—Ä—ã –¥–ª—è –¥–æ–º–∞", "–î–æ–º/–ú–µ–±–µ–ª—å", "–î–æ–º/–û—Å–≤–µ—â–µ–Ω–∏–µ", "–î–∞—á–∞ –∏ —Å–∞–¥",
            "–°–ø–æ—Ä—Ç", "–°–ø–æ—Ä—Ç/–§–∏—Ç–Ω–µ—Å", "–°–ø–æ—Ä—Ç/–¢—É—Ä–∏–∑–º", "–î–µ—Ç—è–º", "–î–µ—Ç—è–º/–û–¥–µ–∂–¥–∞",
            "–î–µ—Ç—è–º/–ò–≥—Ä—É—à–∫–∏", "–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã", "–•–æ–±–±–∏ –∏ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ", "–ö–Ω–∏–≥–∏", 
            "–ü—Ä–æ–¥—É–∫—Ç—ã", "–Æ–≤–µ–ª–∏—Ä–Ω—ã–µ —É–∫—Ä–∞—à–µ–Ω–∏—è", "–ë—ã—Ç–æ–≤–∞—è —Ö–∏–º–∏—è", "–ó–æ–æ—Ç–æ–≤–∞—Ä—ã"
        ]
    } 