import logging
import statistics
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import asyncio
import aiohttp
from io import BytesIO

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

router = APIRouter(tags=["seller_analysis"])

# === –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ===

class SellerAnalysisRequest(BaseModel):
    brand: str
    date_from: str
    date_to: str
    fbs: int = 0

class SellerDetail(BaseModel):
    name: str
    seller_id: int
    items: int
    items_with_sells: int
    items_with_sells_percent: float
    brands_count: int
    brands_with_sells: int
    brands_with_sells_percent: float
    sales: int
    revenue: float
    avg_sales_per_item: float
    avg_sales_per_item_with_sells: float
    avg_revenue_per_item: float
    avg_revenue_per_item_with_sells: float
    stock_end_period: int
    avg_price: float
    avg_rating: float
    avg_feedbacks: float
    position: int
    sales_graph: List[float]
    graph_dates: List[str]
    status: str  # üî• –¢–æ–ø-–ø—Ä–æ–¥–∞–≤–µ—Ü, üöÄ –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π, üìâ –°–ª–∞–±–∞—è –¥–∏–Ω–∞–º–∏–∫–∞
    profit_margin: float

class SellerAnalytics(BaseModel):
    total_sellers: int
    total_revenue: float
    total_sales: int
    avg_items_per_seller: float
    avg_revenue_per_seller: float
    top_seller_revenue: float
    avg_rating: float
    sellers_with_sales_percentage: float

class SellerRecommendations(BaseModel):
    recommended_sellers: List[str]
    avoid_sellers: List[str]
    budget_recommendations: str
    high_margin_sellers: List[str]
    low_risk_sellers: List[str]
    expansion_opportunities: List[str]
    optimization_suggestions: List[str]

class SellerAnalysisResponse(BaseModel):
    sellers: List[SellerDetail]
    analytics: SellerAnalytics
    recommendations: SellerRecommendations
    top_5_sellers: List[SellerDetail]
    total_found: int
    search_params: SellerAnalysisRequest

# === –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å MPStats API ===

async def fetch_mpstats_sellers_data(brand: str, date_from: str, date_to: str, fbs: int) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –∏–∑ MPStats API"""
    
    url = "https://mpstats.io/api/wb/get/brand"
    headers = {
        'X-Mpstats-TOKEN': '68431d2ac72ea4.96910328a56006b24a55daf65db03835d5fe5b4d',
        'Content-Type': 'application/json'
    }
    params = {
        'd1': date_from,
        'd2': date_to,
        'path': brand,
        'fbs': fbs
    }
    
    logger.info(f"üöÄ Starting seller analysis for brand: {brand}")
    logger.info(f"üöÄ Fetching sellers data: {url} with params {params}")
    
    async with aiohttp.ClientSession() as session:
        async with session.get(url, headers=headers, params=params) as response:
            logger.info(f"üìä MPStats sellers API response: {response.status}")
            
            if response.status == 200:
                data = await response.json()
                logger.info(f"‚úÖ Successfully fetched sellers data: {len(data.get('data', []))} sellers")
                return data
            else:
                error_text = await response.text()
                logger.error(f"‚ùå Error fetching sellers data: {response.status} - {error_text}")
                raise HTTPException(status_code=response.status, detail=f"Failed to fetch sellers data: {error_text}")

def generate_dates_for_period(date_from: str, date_to: str, data_length: int = 30) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–∞—Ç –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞"""
    
    try:
        start_date = datetime.fromisoformat(date_from)
        end_date = datetime.fromisoformat(date_to)
        
        period_days = (end_date - start_date).days + 1
        actual_length = min(data_length, period_days, 30)
        
        dates = []
        for i in range(actual_length):
            current_date = end_date - timedelta(days=actual_length - 1 - i)
            dates.append(current_date.strftime("%Y-%m-%d"))
        
        return dates
    except Exception as e:
        logger.warning(f"Error generating dates: {e}")
        today = datetime.now()
        return [(today - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(29, -1, -1)]

def determine_seller_status(seller: Dict, avg_revenue: float, avg_sales: float) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞"""
    
    revenue = seller.get('revenue', 0)
    sales = seller.get('sales', 0)
    rating = seller.get('avg_rating', 0)
    items_with_sells_percent = seller.get('items_with_sells_percent', 0)
    
    # –¢–æ–ø-–ø—Ä–æ–¥–∞–≤–µ—Ü: –≤—ã—Ä—É—á–∫–∞ –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–π –Ω–∞ 50%+ –∏ —Ö–æ—Ä–æ—à–∏–π —Ä–µ–π—Ç–∏–Ω–≥
    if revenue > avg_revenue * 1.5 and rating >= 4.0 and items_with_sells_percent > 60:
        return "üî• –¢–æ–ø-–ø—Ä–æ–¥–∞–≤–µ—Ü"
    
    # –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π: –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º –∏–ª–∏ –≤—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —Ç–æ–≤–∞—Ä–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏
    elif (revenue > avg_revenue or items_with_sells_percent > 70) and rating >= 3.8:
        return "üöÄ –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π"
    
    # –°–ª–∞–±–∞—è –¥–∏–Ω–∞–º–∏–∫–∞: –Ω–∏–∑–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    elif revenue < avg_revenue * 0.5 or items_with_sells_percent < 30:
        return "üìâ –°–ª–∞–±–∞—è –¥–∏–Ω–∞–º–∏–∫–∞"
    
    # –°—Ç–∞–±–∏–ª—å–Ω—ã–π: —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    else:
        return "üìä –°—Ç–∞–±–∏–ª—å–Ω—ã–π"

def calculate_profit_margin(seller: Dict) -> float:
    """–†–∞—Å—á–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ–π –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞"""
    
    avg_price = seller.get('avg_price', 0)
    avg_sales_per_item = seller.get('avg_sales_per_item_with_sells', 0)
    
    if avg_price > 0 and avg_sales_per_item > 0:
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω—ã –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç–∏
        if avg_price > 2000 and avg_sales_per_item > 10:
            return 0.35  # –í—ã—Å–æ–∫–∞—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        elif avg_price > 1000 and avg_sales_per_item > 5:
            return 0.25  # –°—Ä–µ–¥–Ω—è—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        elif avg_price > 500:
            return 0.15  # –ù–∏–∑–∫–∞—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        else:
            return 0.10  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    
    return 0.20  # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

def process_sellers_data(raw_data: Dict, date_from: str, date_to: str) -> List[SellerDetail]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤"""
    
    sellers_data = raw_data.get('data', [])
    
    if not sellers_data:
        return []
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤
    avg_revenue = statistics.mean([s.get('revenue', 0) for s in sellers_data])
    avg_sales = statistics.mean([s.get('sales', 0) for s in sellers_data])
    
    processed_sellers = []
    
    for idx, seller in enumerate(sellers_data):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –ø—Ä–æ–¥–∞–∂
        sales_graph_data = seller.get('graph', [])
        if isinstance(sales_graph_data, list):
            sales_graph = [float(val) if val else 0.0 for val in sales_graph_data[:30]]
        else:
            sales_graph = [0.0] * 30
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞—Ç—ã –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
        graph_dates = generate_dates_for_period(date_from, date_to, len(sales_graph))
        
        # Ensure lists are same length
        if len(sales_graph) != len(graph_dates):
            min_length = min(len(sales_graph), len(graph_dates))
            sales_graph = sales_graph[:min_length]
            graph_dates = graph_dates[:min_length]
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        items = seller.get('items', 0)
        items_with_sells = seller.get('items_with_sells', 0)
        brands_count = seller.get('brands_count', 0)
        brands_with_sells = seller.get('brands_with_sells', 0)
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
        items_with_sells_percent = (items_with_sells / items * 100) if items > 0 else 0
        brands_with_sells_percent = (brands_with_sells / brands_count * 100) if brands_count > 0 else 0
        
        # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        sales = seller.get('sales', 0)
        revenue = seller.get('revenue', 0)
        avg_sales_per_item = sales / items if items > 0 else 0
        avg_sales_per_item_with_sells = sales / items_with_sells if items_with_sells > 0 else 0
        avg_revenue_per_item = revenue / items if items > 0 else 0
        avg_revenue_per_item_with_sells = revenue / items_with_sells if items_with_sells > 0 else 0
        
        processed_seller = SellerDetail(
            name=seller.get('name', f'–ü—Ä–æ–¥–∞–≤–µ—Ü {idx + 1}'),
            seller_id=seller.get('supplierid', idx),
            items=items,
            items_with_sells=items_with_sells,
            items_with_sells_percent=round(items_with_sells_percent, 1),
            brands_count=brands_count,
            brands_with_sells=brands_with_sells,
            brands_with_sells_percent=round(brands_with_sells_percent, 1),
            sales=sales,
            revenue=revenue,
            avg_sales_per_item=round(avg_sales_per_item, 1),
            avg_sales_per_item_with_sells=round(avg_sales_per_item_with_sells, 1),
            avg_revenue_per_item=round(avg_revenue_per_item, 2),
            avg_revenue_per_item_with_sells=round(avg_revenue_per_item_with_sells, 2),
            stock_end_period=seller.get('stock_end_period', 0),
            avg_price=round(seller.get('avg_price', 0), 2),
            avg_rating=round(seller.get('avg_rating', 0), 1),
            avg_feedbacks=round(seller.get('avg_feedbacks', 0), 1),
            position=seller.get('position', idx + 1),
            sales_graph=sales_graph,
            graph_dates=graph_dates,
            status=determine_seller_status(seller, avg_revenue, avg_sales),
            profit_margin=calculate_profit_margin(seller)
        )
        
        processed_sellers.append(processed_seller)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—ã—Ä—É—á–∫–µ
    processed_sellers.sort(key=lambda x: x.revenue, reverse=True)
    
    return processed_sellers

def generate_seller_analytics(sellers: List[SellerDetail]) -> SellerAnalytics:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ –ø—Ä–æ–¥–∞–≤—Ü–∞–º"""
    
    if not sellers:
        return SellerAnalytics(
            total_sellers=0,
            total_revenue=0,
            total_sales=0,
            avg_items_per_seller=0,
            avg_revenue_per_seller=0,
            top_seller_revenue=0,
            avg_rating=0,
            sellers_with_sales_percentage=0
        )
    
    total_sellers = len(sellers)
    total_revenue = sum(s.revenue for s in sellers)
    total_sales = sum(s.sales for s in sellers)
    avg_items_per_seller = statistics.mean([s.items for s in sellers])
    avg_revenue_per_seller = total_revenue / total_sellers
    top_seller_revenue = max(s.revenue for s in sellers)
    
    ratings = [s.avg_rating for s in sellers if s.avg_rating > 0]
    avg_rating = statistics.mean(ratings) if ratings else 0
    
    sellers_with_sales = sum(1 for s in sellers if s.sales > 0)
    sellers_with_sales_percentage = (sellers_with_sales / total_sellers) * 100
    
    return SellerAnalytics(
        total_sellers=total_sellers,
        total_revenue=total_revenue,
        total_sales=total_sales,
        avg_items_per_seller=round(avg_items_per_seller, 1),
        avg_revenue_per_seller=round(avg_revenue_per_seller, 2),
        top_seller_revenue=top_seller_revenue,
        avg_rating=round(avg_rating, 1),
        sellers_with_sales_percentage=round(sellers_with_sales_percentage, 1)
    )

async def generate_seller_recommendations(
    brand: str, 
    sellers: List[SellerDetail], 
    analytics: SellerAnalytics
) -> SellerRecommendations:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø—Ä–æ–¥–∞–≤—Ü–∞–º"""
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key="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")
        
        # –¢–æ–ø –ø—Ä–æ–¥–∞–≤—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        top_sellers = sellers[:5]
        worst_sellers = sellers[-3:] if len(sellers) > 3 else []
        
        context = f"""
–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –¥–ª—è –±—Ä–µ–Ω–¥–∞: {brand}
–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤: {analytics.total_sellers}
- –û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: {analytics.total_revenue:,.0f} ‚ÇΩ
- –û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏: {analytics.total_sales:,} —à—Ç.
- –°—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞ –Ω–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞: {analytics.avg_revenue_per_seller:,.0f} ‚ÇΩ
- –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {analytics.avg_rating:.1f}/5
- –ü—Ä–æ–¥–∞–≤—Ü–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏: {analytics.sellers_with_sales_percentage:.1f}%

–¢–æ–ø-5 –ø—Ä–æ–¥–∞–≤—Ü–æ–≤:
{chr(10).join([f"{i+1}. {s.name}: {s.revenue:,.0f} ‚ÇΩ –≤—ã—Ä—É—á–∫–∏, {s.items} —Ç–æ–≤–∞—Ä–æ–≤, {s.avg_rating:.1f}‚òÖ, {s.status}" for i, s in enumerate(top_sellers)])}

–°–ª–∞–±—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã:
{chr(10).join([f"- {s.name}: {s.revenue:,.0f} ‚ÇΩ –≤—ã—Ä—É—á–∫–∏, {s.items_with_sells_percent:.1f}% —Ç–æ–≤–∞—Ä–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏" for s in worst_sellers])}
"""

        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–æ–º –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤. –î–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–±–æ—Ç–µ —Å –ø—Ä–æ–¥–∞–≤—Ü–∞–º–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
                },
                {
                    "role": "user",
                    "content": f"{context}\n\n–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n1. –° –∫–∞–∫–∏–º–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞–º–∏ —É—Å–∏–ª–∏—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ\n2. –û—Ç –∫–∞–∫–∏—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ —Å—Ç–æ–∏—Ç –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è\n3. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –±—é–¥–∂–µ—Ç –Ω–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n4. –ü—Ä–æ–¥–∞–≤—Ü—ã —Å –≤—ã—Å–æ–∫–æ–π –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é\n5. –ü—Ä–æ–¥–∞–≤—Ü—ã —Å –Ω–∏–∑–∫–∏–º —Ä–∏—Å–∫–æ–º\n6. –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞\n7. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"
                }
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        ai_text = response.choices[0].message.content
        
        return parse_seller_recommendations(ai_text, sellers)
        
    except Exception as e:
        logger.warning(f"Failed to generate AI recommendations: {e}")
        return generate_fallback_seller_recommendations(sellers, analytics)

def parse_seller_recommendations(ai_text: str, sellers: List[SellerDetail]) -> SellerRecommendations:
    """–ü–∞—Ä—Å–∏–Ω–≥ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ (—Ç–æ–ø –ø–æ –≤—ã—Ä—É—á–∫–µ)
        recommended = [s.name for s in sellers[:3] if s.status in ["üî• –¢–æ–ø-–ø—Ä–æ–¥–∞–≤–µ—Ü", "üöÄ –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π"]]
        
        # –ü—Ä–æ–¥–∞–≤—Ü–æ–≤ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è (—Å–ª–∞–±—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏)
        avoid = [s.name for s in sellers if s.status == "üìâ –°–ª–∞–±–∞—è –¥–∏–Ω–∞–º–∏–∫–∞"][:3]
        
        # –í—ã—Å–æ–∫–æ–º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã
        high_margin = [s.name for s in sellers if s.profit_margin > 0.25][:3]
        
        # –ù–∏–∑–∫–æ—Ä–∏—Å–∫–æ–≤—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã (—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏ –∏ –æ—Å—Ç–∞—Ç–∫–∏)
        low_risk = [s.name for s in sellers if s.avg_rating >= 4.0 and s.items_with_sells_percent > 60][:3]
        
        return SellerRecommendations(
            recommended_sellers=recommended,
            avoid_sellers=avoid,
            budget_recommendations="–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –±—é–¥–∂–µ—Ç –Ω–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–¥–∞–≤—Ü–∞: 50-150–ö ‚ÇΩ",
            high_margin_sellers=high_margin,
            low_risk_sellers=low_risk,
            expansion_opportunities=[
                f"–†–∞—Å—à–∏—Ä–∏—Ç—å –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç —É {sellers[0].name}" if sellers else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–î–æ–±–∞–≤–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö",
                "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –±—Ä–µ–Ω–¥—ã —É —Ç–æ–ø-–ø—Ä–æ–¥–∞–≤—Ü–æ–≤"
            ],
            optimization_suggestions=[
                "–£–±—Ä–∞—Ç—å –Ω–µ–ª–∏–∫–≤–∏–¥–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã —É —Å–ª–∞–±—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤",
                "–£–≤–µ–ª–∏—á–∏—Ç—å –∑–∞–∫—É–ø–∫–∏ —É —Ç–æ–ø-–ø—Ä–æ–¥–∞–≤—Ü–æ–≤",
                "–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —É—Å–ª–æ–≤–∏—è —Å –ø—Ä–æ–¥–∞–≤—Ü–∞–º–∏ –Ω–∏–∑–∫–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"
            ]
        )
        
    except Exception as e:
        logger.warning(f"Failed to parse AI recommendations: {e}")
        return generate_fallback_seller_recommendations(sellers, SellerAnalytics(
            total_sellers=0, total_revenue=0, total_sales=0,
            avg_items_per_seller=0, avg_revenue_per_seller=0,
            top_seller_revenue=0, avg_rating=0, sellers_with_sales_percentage=0
        ))

def generate_fallback_seller_recommendations(sellers: List[SellerDetail], analytics: SellerAnalytics) -> SellerRecommendations:
    """Fallback —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ AI"""
    
    recommended = [s.name for s in sellers[:3]]
    avoid = [s.name for s in sellers if s.revenue < analytics.avg_revenue_per_seller * 0.3][:2]
    high_margin = [s.name for s in sellers if s.profit_margin > 0.25][:3]
    low_risk = [s.name for s in sellers if s.avg_rating >= 4.0][:3]
    
    return SellerRecommendations(
        recommended_sellers=recommended,
        avoid_sellers=avoid,
        budget_recommendations=f"–°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç –Ω–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞: {analytics.avg_revenue_per_seller:,.0f} ‚ÇΩ",
        high_margin_sellers=high_margin,
        low_risk_sellers=low_risk,
        expansion_opportunities=["–†–∞—Å—à–∏—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —Ç–æ–ø-–ø—Ä–æ–¥–∞–≤—Ü–∞–º–∏", "–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"],
        optimization_suggestions=["–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–ª–∞–±—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤", "–£–≤–µ–ª–∏—á–∏—Ç—å –∑–∞–∫—É–ø–∫–∏ —É –ª–∏–¥–µ—Ä–æ–≤"]
    )

def apply_seller_filters(sellers: List[SellerDetail], filters: Dict[str, Any]) -> List[SellerDetail]:
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∫ –ø—Ä–æ–¥–∞–≤—Ü–∞–º"""
    
    filtered = sellers
    
    if filters.get('min_items'):
        filtered = [s for s in filtered if s.items >= filters['min_items']]
    
    if filters.get('min_revenue'):
        filtered = [s for s in filtered if s.revenue >= filters['min_revenue']]
    
    if filters.get('min_rating'):
        filtered = [s for s in filtered if s.avg_rating >= filters['min_rating']]
    
    if filters.get('max_stock'):
        filtered = [s for s in filtered if s.stock_end_period <= filters['max_stock']]
    
    if filters.get('min_sells_percent'):
        filtered = [s for s in filtered if s.items_with_sells_percent >= filters['min_sells_percent']]
    
    return filtered

@router.post("/analyze", response_model=SellerAnalysisResponse)
async def analyze_sellers(request: SellerAnalysisRequest):
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –ø–æ –±—Ä–µ–Ω–¥—É"""
    
    try:
        logger.info(f"üéØ Seller analysis request for brand: {request.brand}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ MPStats API
        raw_data = await fetch_mpstats_sellers_data(
            request.brand, 
            request.date_from, 
            request.date_to, 
            request.fbs
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
        sellers = process_sellers_data(raw_data, request.date_from, request.date_to)
        
        if not sellers:
            logger.warning(f"‚ö†Ô∏è No sellers found for brand: {request.brand}")
            raise HTTPException(status_code=404, detail=f"No sellers found for brand '{request.brand}' in the specified period.")
        
        logger.info(f"üìä Processing {len(sellers)} sellers for brand analysis")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        analytics = generate_seller_analytics(sellers)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = await generate_seller_recommendations(request.brand, sellers, analytics)
        
        # –¢–æ–ø-5 –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
        top_5_sellers = sellers[:5]
        
        logger.info(f"‚úÖ Seller analysis completed successfully for brand: {request.brand}")
        
        return SellerAnalysisResponse(
            sellers=sellers,
            analytics=analytics,
            recommendations=recommendations,
            top_5_sellers=top_5_sellers,
            total_found=len(sellers),
            search_params=request
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in seller analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router.post("/export")
async def export_sellers_xlsx(request: SellerAnalysisRequest):
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ –≤ XLSX —Ñ–∞–π–ª"""
    
    try:
        import pandas as pd
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
        raw_data = await fetch_mpstats_sellers_data(
            request.brand, 
            request.date_from, 
            request.date_to, 
            request.fbs
        )
        
        sellers = process_sellers_data(raw_data, request.date_from, request.date_to)
        
        if not sellers:
            raise HTTPException(status_code=404, detail="No sellers found for export")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        export_data = []
        for seller in sellers:
            export_data.append({
                'Name': seller.name,
                'Seller_ID': seller.seller_id,
                'Items': seller.items,
                'Items_With_Sells': seller.items_with_sells,
                'Items_With_Sells_Percent': seller.items_with_sells_percent,
                'Brands_Count': seller.brands_count,
                'Brands_With_Sells': seller.brands_with_sells,
                'Brands_With_Sells_Percent': seller.brands_with_sells_percent,
                'Sales': seller.sales,
                'Revenue': seller.revenue,
                'Avg_Sales_Per_Item': seller.avg_sales_per_item,
                'Avg_Sales_Per_Item_With_Sells': seller.avg_sales_per_item_with_sells,
                'Avg_Revenue_Per_Item': seller.avg_revenue_per_item,
                'Avg_Revenue_Per_Item_With_Sells': seller.avg_revenue_per_item_with_sells,
                'Stock_End_Period': seller.stock_end_period,
                'Avg_Price': seller.avg_price,
                'Avg_Rating': seller.avg_rating,
                'Avg_Feedbacks': seller.avg_feedbacks,
                'Position': seller.position,
                'Status': seller.status,
                'Profit_Margin': seller.profit_margin
            })
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(export_data)
        
        # –°–æ–∑–¥–∞–µ–º XLSX —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, sheet_name='Sellers_Analysis', index=False)
            
            # –ü–æ–ª—É—á–∞–µ–º workbook –∏ worksheet –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            workbook = writer.book
            worksheet = writer.sheets['Sellers_Analysis']
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            header_format = workbook.add_format({
                'bold': True,
                'text_wrap': True,
                'valign': 'top',
                'fg_color': '#667eea',
                'font_color': 'white',
                'border': 1
            })
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
            for col_num, value in enumerate(df.columns.values):
                worksheet.write(0, col_num, value, header_format)
                
            # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
            for i, col in enumerate(df.columns):
                max_length = max(
                    df[col].astype(str).str.len().max(),
                    len(str(col))
                )
                worksheet.set_column(i, i, min(max_length + 2, 50))
        
        output.seek(0)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª
        filename = f"sellers_{request.brand}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        return StreamingResponse(
            BytesIO(output.getvalue()), 
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            headers={'Content-Disposition': f'attachment; filename="{filename}"'}
        )
        
    except ImportError:
        raise HTTPException(status_code=500, detail="Excel export requires pandas and xlsxwriter packages")
    except Exception as e:
        logger.error(f"Error in seller export: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in seller export: {str(e)}")

@router.get("/brands")
async def get_popular_brands():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    return {
        "brands": [
            "Nike", "Adidas", "Apple", "Samsung", "Xiaomi",
            "H&M", "Zara", "Uniqlo", "IKEA", "Philips",
            "Sony", "LG", "Bosch", "Siemens", "Panasonic"
        ]
    } 