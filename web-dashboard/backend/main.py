from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, EmailStr
from typing import List, Optional, Dict, Any
import jwt
import bcrypt
import sqlite3
import sys
import os
import json
# Ensure project root in sys.path for modules outside backend (e.g., supply_planning.py at repo root)
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)
from datetime import datetime, timedelta
import asyncio
import logging

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Wildberries
from wb_api import get_wb_product_info, format_product_analysis, generate_recommendations, analyze_competition, search_competitors, get_brand_analysis
from supplier_analysis import get_supplier_analysis, format_supplier_message
from oracle_queries import OracleQueries
from global_search import global_search_serper_detailed
from seasonality_analysis import get_seasonality_analysis

# AI generation
from ai_generation import generate_ai_content  # type: ignore
from config import OPENAI_API_KEY  # type: ignore

# Supply planning
from supply_planning import supply_planner, format_supply_planning_report  # type: ignore
from blogger_search import search_bloggers_by_query, format_blogger_search_results  # type: ignore

# patch for circular import with new_bot
import sys, types
import os
# Provide dummy 'main' module so that new_bot import works without circular dependency
if 'main' not in sys.modules:
    _dummy = types.ModuleType('main')
    _dummy.ProductCardAnalyzer = object  # placeholder to satisfy new_bot import
    _dummy.TrendAnalyzer = object
    _dummy.app = None  # –±—É–¥–µ—Ç –∑–∞–º–µ–Ω—ë–Ω —Ä–µ–∞–ª—å–Ω—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º FastAPI –Ω–∏–∂–µ
    sys.modules['main'] = _dummy
else:
    # If already present (e.g., during reload), ensure attributes exist
    dummy_main = sys.modules['main']
    if not hasattr(dummy_main, 'ProductCardAnalyzer'):
        dummy_main.ProductCardAnalyzer = object
    if not hasattr(dummy_main, 'TrendAnalyzer'):
        dummy_main.TrendAnalyzer = object
    if not hasattr(dummy_main, 'app'):
        dummy_main.app = None

# –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ bot –º–æ–¥—É–ª—è (–Ω–∞–º –Ω–µ –Ω—É–∂–µ–Ω –±–æ—Ç –≤ web-dashboard)
async def get_external_ads_data(query: str):
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–ª–∞–º—ã"""
    return {
        "query": query,
        "external_ads": [],
        "social_media_posts": [],
        "influencer_content": [],
        "status": "external_analysis_disabled_for_web_dashboard"
    }

def format_external_analysis(data):
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–Ω–µ—à–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    summary = f"–í–Ω–µ—à–Ω–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è '{data.get('query', '')}' –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –≤ web-dashboard"
    return summary, data

# Import functions after dummy module registered
# –û—Ç–∫–ª—é—á–∞–µ–º –∏–º–ø–æ—Ä—Ç –±–æ—Ç–∞ –¥–ª—è web-dashboard - –æ–Ω –Ω–∞–º –Ω–µ –Ω—É–∂–µ–Ω
# from new_bot import get_external_ads_data, format_external_analysis  # type: ignore

# Import the new MPStats analysis routes
from routes.mpstats_analysis import router as mpstats_router
from routes.brand_analysis import router as brand_router
from routes.category_analysis import router as category_router
from routes.blogger_search import router as blogger_router
from routes.supplier_analysis import router as seller_router
from routes.oracle_analysis import router as oracle_router

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Whitesamurai Web App",
    description="Analytics dashboard for e-commerce data",
    version="2.0.0"
)
# –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π –º–æ–¥—É–ª—å, —á—Ç–æ–±—ã Uvicorn –º–æ–≥ –Ω–∞–π—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
sys.modules['main'].app = app

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# JWT –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
SECRET_KEY = "your-secret-key-here"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30 * 24 * 60  # 30 –¥–Ω–µ–π

security = HTTPBearer()

# –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
DATABASE_PATH = "users.db"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Oracle (–∞–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
oracle = OracleQueries()

# Pydantic –º–æ–¥–µ–ª–∏
class UserLogin(BaseModel):
    email: EmailStr
    password: str

class UserRegister(BaseModel):
    email: EmailStr
    password: str
    telegram_id: Optional[int] = None

class ProductAnalysisRequest(BaseModel):
    article: str

class BrandAnalysisRequest(BaseModel):
    brand_name: str

class AdMonitoringRequest(BaseModel):
    articles: List[str]
    manual_data: Optional[Dict[str, Any]] = None

class PasswordChangeRequest(BaseModel):
    new_password: str

class SubscriptionUpgradeRequest(BaseModel):
    plan: str

class SupplierAnalysisRequest(BaseModel):
    supplier_name: str

class CategoryAnalysisRequest(BaseModel):
    category_name: str
    month: Optional[str] = None  # —Ñ–æ—Ä–º–∞—Ç YYYY-MM, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–µ–∫—É—â–∏–π –º–µ—Å—è—Ü

class GlobalSearchRequest(BaseModel):
    query: str

# –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
class SeasonalityAnalysisRequest(BaseModel):
    category: str  # Wildberries category path, e.g. "–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª–∞—Ç—å—è/–ö–æ–∫—Ç–µ–π–ª—å–Ω—ã–µ"

# ==== AI Helper ====
class AIHelperRequest(BaseModel):
    content_type: str  # e.g. 'product_description', 'product_card', etc.
    prompt: str        # user input / description for generation

# ==== Supply Planning ====
class SupplyPlanningRequest(BaseModel):
    articles: List[str]

class EnhancedSupplyPlanningRequest(BaseModel):
    articles: List[str]
    target_stock_days: Optional[int] = 15  # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π —Ü–µ–ª–µ–≤–æ–π –∑–∞–ø–∞—Å

# ==== Blogger Search ====
class BloggerSearchRequest(BaseModel):
    query: str

# ==== External Analysis ====
class ExternalAnalysisRequest(BaseModel):
    query: str

class OracleMainRequest(BaseModel):
    queries_count: int = 3  # 1-5
    month: str              # format YYYY-MM
    min_revenue: int = 0
    min_frequency: int = 0

class EnhancedOracleRequest(BaseModel):
    queries_count: int = 3  # 1-5
    month: str              # format YYYY-MM
    min_revenue: int = 0
    min_frequency: int = 0
    oracle_type: str = "products"  # products, brands, suppliers, categories, search_queries
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
    category_filter: Optional[str] = None
    brand_filter: Optional[str] = None
    supplier_filter: Optional[str] = None

# –§—É–Ω–∫—Ü–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
def hash_password(password: str) -> str:
    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')

def verify_password(password: str, hashed: str) -> bool:
    return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        email: str = payload.get("sub")
        if email is None:
            raise HTTPException(status_code=401, detail="Invalid token")
        return email
    except jwt.PyJWTError:
        raise HTTPException(status_code=401, detail="Invalid token")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def init_db():
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS web_users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            email TEXT UNIQUE NOT NULL,
            password_hash TEXT NOT NULL,
            telegram_id INTEGER,
            balance REAL DEFAULT 1000.0,
            subscription_type TEXT DEFAULT 'Pro',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_login TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            total_analyses INTEGER DEFAULT 0
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_operations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_email TEXT NOT NULL,
            type TEXT NOT NULL,
            description TEXT NOT NULL,
            amount REAL NOT NULL,
            status TEXT DEFAULT 'completed',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_email) REFERENCES web_users (email)
        )
    ''')
    
    test_password = hash_password("testpassword")
    cursor.execute('''
        INSERT OR REPLACE INTO web_users (email, password_hash, balance, subscription_type, total_analyses)
        VALUES (?, ?, ?, ?, ?)
    ''', ("test@example.com", test_password, 1000.0, "Pro", 156))
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    cursor.execute('''
        INSERT OR REPLACE INTO user_operations (user_email, type, description, amount, created_at)
        VALUES 
        ('test@example.com', 'analysis', '–ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–∞ #275191790', -50, '2024-07-03 10:15:00'),
        ('test@example.com', 'subscription', '–ü—Ä–æ–¥–ª–µ–Ω–∏–µ Pro –ø–æ–¥–ø–∏—Å–∫–∏', -1990, '2024-07-01 09:00:00'),
        ('test@example.com', 'bonus', '–ë–æ–Ω—É—Å –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é', 1000, '2024-06-15 14:20:00'),
        ('test@example.com', 'analysis', '–ê–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–∞ Apple', -100, '2024-06-20 16:45:00')
    ''')
    
    conn.commit()
    conn.close()

def generate_fallback_category_recommendations(summary: str) -> Dict[str, Any]:
    """–ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø–∞—Ä—Å–µ—Ä summary ‚Üí –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 5 –ø–ª—é—Å–æ–≤ –∏ 5 –º–∏–Ω—É—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤."""
    plus = [
        "–í—ã—Å–æ–∫–∏–π —Å–ø—Ä–æ—Å –≤ —Ç–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞",
        "–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç",
        "–°—Ç–∞–±–∏–ª—å–Ω—ã–π —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫",
        "–í—ã—Å–æ–∫–∞—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π",
        "–ë–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ (—Ä–∏—Å–∫/–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å)"
    ]
    minus = [
        "–í—ã—Å–æ–∫–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è",
        "–ù–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂ –ø–æ —Å–µ–∑–æ–Ω—É",
        "–í—ã—Å–æ–∫–∏–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã",
        "–°–ª–æ–∂–Ω–æ—Å—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–æ–º",
        "–ù–∏–∑–∫–∞—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π"
    ]
    return {"pluses": plus[:5], "minuses": minus[:5], "score": 3.5}

async def generate_category_recommendations(summary: str) -> Dict[str, Any]:
    try:
        import openai
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return generate_fallback_category_recommendations(summary)
        client = openai.AsyncOpenAI(api_key=api_key)
        prompt = (
            "–¢—ã ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç Wildberries. –ü—Ä–æ—á–∏—Ç–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –ø–µ—Ä–µ—á–∏—Å–ª–∏ 5 –ø–ª—é—Å–∞—Ö –∏ 5 –º–∏–Ω—É—Å–∞—Ö, "
            "–∞ –∑–∞—Ç–µ–º –¥–∞–π –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ 5-–±–∞–ª–ª—å–Ω–æ–π —à–∫–∞–ª–µ (—Ü–µ–ª–æ–µ –∏–ª–∏ —Å –ø–æ–ª–æ–≤–∏–Ω–æ–π). "
            "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ JSON —Å –∫–ª—é—á–∞–º–∏ pluses, minuses, score.\n\n"
            f"–û–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:\n{summary}\n"
        )
        chat = await client.chat.completions.create(
            model="gpt-3.5-turbo-0613",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=400,
            temperature=0.6
        )
        raw = chat.choices[0].message.content
        try:
            data = json.loads(raw)
            if all(k in data for k in ("pluses", "minuses", "score")):
                return data
        except Exception:
            pass
        return generate_fallback_category_recommendations(summary)
    except Exception:
        return generate_fallback_category_recommendations(summary)

# –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
@app.post("/auth/register")
async def register(user: UserRegister):
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    try:
        hashed_password = hash_password(user.password)
        cursor.execute('''
            INSERT INTO web_users (email, password_hash, telegram_id)
            VALUES (?, ?, ?)
        ''', (user.email, hashed_password, user.telegram_id))
        
        conn.commit()
        return {"message": "User registered successfully"}
    except sqlite3.IntegrityError:
        raise HTTPException(status_code=400, detail="Email already registered")
    finally:
        conn.close()

@app.post("/auth/login")
async def login(user: UserLogin):
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    cursor.execute("SELECT password_hash FROM web_users WHERE email = ?", (user.email,))
    result = cursor.fetchone()
    conn.close()
    
    if not result or not verify_password(user.password, result[0]):
        raise HTTPException(status_code=401, detail="Invalid email or password")
    
    access_token = create_access_token(data={"sub": user.email})
    return {"access_token": access_token, "token_type": "bearer"}

@app.get("/auth/verify")
async def verify_token(email: str = Depends(get_current_user)):
    return {"email": email, "valid": True}

# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
@app.get("/user/dashboard")
async def get_dashboard_data(email: str = Depends(get_current_user)):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∂–∏–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏."""
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()

    # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    cursor.execute(
        """
        SELECT email, balance, subscription_type
        FROM web_users WHERE email = ?
        """,
        (email,)
    )
    user_row = cursor.fetchone()
    if not user_row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")

    # –ü–æ–¥—Å—á—ë—Ç –¥–µ–π—Å—Ç–≤–∏–π
    def count_ops(op_type: str) -> int:
        cursor.execute(
            "SELECT COUNT(*) FROM user_operations WHERE user_email = ? AND type = ?",
            (email, op_type),
        )
        return cursor.fetchone()[0] or 0

    products_cnt = count_ops("product")
    brands_cnt = count_ops("brand")
    niches_cnt = count_ops("niche")  # –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω—ã—Ö –±—É–¥—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫
    ai_helper_cnt = count_ops("ai_helper")

    # –≠–∫–æ–Ω–æ–º–∏—è = 133‚ÇΩ –∑–∞ –∫–∞–∂–¥–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    block_types = (
        'product','brand','niche','supplier','category','seasonality',
        'external_analysis','blogger_search','global_search','ai_helper',
        'oracle_queries','supply_planning','ad_monitoring'
    )
    cursor.execute(
        f"SELECT COUNT(*) FROM user_operations WHERE user_email = ? AND type IN ({','.join(['?']*len(block_types))})",
        (email, *block_types),
    )
    blocks_used = cursor.fetchone()[0] or 0
    total_savings = blocks_used * 133

    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 –æ–ø–µ—Ä–∞—Ü–∏–∏ (product/brand/niche) –¥–ª—è –ª–µ–Ω—Ç—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    cursor.execute(
        """
        SELECT type, description, created_at
        FROM user_operations
        WHERE user_email = ? AND type IN ('product','brand','niche')
        ORDER BY created_at DESC
        LIMIT 3
        """,
        (email,),
    )
    recent_rows = cursor.fetchall()
    recent_activity = [
        {"type": row[0], "item": row[1] or row[0].capitalize(), "date": row[2]} for row in recent_rows
    ]

    conn.close()

    return {
        "user": {
            "email": user_row[0],
            "balance": user_row[1],
            "subscription_type": user_row[2],
        },
        "stats": {
            "products_analyzed": products_cnt,
            "brands_analyzed": brands_cnt,
            "ai_helper_uses": ai_helper_cnt,
            "total_savings": total_savings,
        },
        "recent_activity": recent_activity,
    }

# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
@app.post("/analysis/product")
async def analyze_product(request: ProductAnalysisRequest, email: str = Depends(get_current_user)):
    try:
        logger.info(f"üîß Starting FIXED product analysis for article: {request.article}")
        
        # üîß –ò–°–ü–û–õ–¨–ó–£–ï–ú –ò–°–ü–†–ê–í–õ–ï–ù–ù–£–Æ –§–£–ù–ö–¶–ò–Æ
        try:
            from wb_api_fixed import get_wb_product_info_fixed
            logger.info(f"‚úÖ Using fixed WB API integration for {request.article}")
            product_info = await get_wb_product_info_fixed(request.article)
        except ImportError:
            # Fallback –∫ —Å—Ç–∞—Ä–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            logger.warning("‚ö†Ô∏è Fixed module not available, using original")
            product_info = await get_wb_product_info(request.article)
        
        if not product_info:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            logger.warning(f"No product data found for {request.article}, creating fallback")
            product_info = {
                'article': request.article,
                'name': f'–¢–æ–≤–∞—Ä {request.article}',
                'brand': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±—Ä–µ–Ω–¥',
                'price': {'current': 1299, 'original': 1499, 'discount': 13},
                'rating': 4.2,
                'reviews_count': 187,
                'stocks': {'total': 156, 'by_size': {}},
                'sales': {
                    'today': 0,
                    'total': 0,
                    'revenue': {'daily': 0, 'weekly': 0, 'monthly': 0, 'total': 0},
                    'profit': {'daily': 0, 'weekly': 0, 'monthly': 0}
                },
                'feedbacks': 187
            }
        
        # üîß –ò–°–ü–û–õ–¨–ó–£–ï–ú –ò–°–ü–†–ê–í–õ–ï–ù–ù–£–Æ –§–£–ù–ö–¶–ò–Æ –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
            from wb_api_fixed import get_mpstats_product_data_fixed
            
            # –ü–æ–ª—É—á–∞–µ–º MPStats –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π API
            logger.info(f"üîß Getting MPStats data using fixed API for {request.article}")
            mpstats_data = await get_mpstats_product_data_fixed(request.article)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º product_info –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ MPStats
            if mpstats_data and mpstats_data.get('daily_sales', 0) > 0:
                product_info['sales'].update({
                    'today': mpstats_data.get('daily_sales', 0),
                    'total': mpstats_data.get('total_sales', 0),
                    'revenue': {
                        'daily': mpstats_data.get('daily_revenue', 0),
                        'weekly': mpstats_data.get('daily_revenue', 0) * 7,
                        'monthly': mpstats_data.get('daily_revenue', 0) * 30,
                        'total': mpstats_data.get('total_revenue', 0)
                    },
                    'profit': {
                        'daily': mpstats_data.get('daily_profit', 0),
                        'weekly': mpstats_data.get('daily_profit', 0) * 7,
                        'monthly': mpstats_data.get('daily_profit', 0) * 30
                    }
                })
                logger.info(f"‚úÖ Product info updated with MPStats data: {mpstats_data.get('daily_sales')} sales/day")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            analysis = await format_product_analysis(product_info, request.article)
            
            # üîß –î–û–ë–ê–í–õ–Ø–ï–ú –û–¢–õ–ê–î–û–ß–ù–£–Æ –ò–ù–§–û–†–ú–ê–¶–ò–Æ
            if mpstats_data:
                analysis['mpstats_debug'] = {
                    'api_status': 'fixed_api_used',
                    'has_sales_data': bool(mpstats_data.get('raw_data')),
                    'daily_sales': mpstats_data.get('daily_sales', 0),
                    'daily_revenue': mpstats_data.get('daily_revenue', 0),
                    'debug_info': mpstats_data.get('debug_info', {})
                }
            else:
                analysis['mpstats_debug'] = {
                    'api_status': 'no_data_received',
                    'message': 'MPStats API returned no data'
                }
                
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Fixed MPStats module not available: {e}, using fallback")
            analysis = await format_product_analysis(product_info, request.article)
            analysis['mpstats_debug'] = {
                'api_status': 'fallback_used',
                'reason': 'fixed_module_not_available'
            }
        except Exception as e:
            logger.error(f"‚ùå Error using fixed MPStats API: {e}")
            analysis = await format_product_analysis(product_info, request.article)
            analysis['mpstats_debug'] = {
                'api_status': 'error',
                'error': str(e)
            }
        
        # üîß –î–û–ë–ê–í–õ–Ø–ï–ú –ú–ï–¢–†–ò–ö–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò
        if mpstats_data:
            analysis['efficiency_metrics'] = {
                'purchase_rate': mpstats_data.get('purchase_rate', 72.5),
                'conversion_rate': mpstats_data.get('conversion_rate', 2.8),
                'market_share': mpstats_data.get('market_share', 0.3)
            }
        
        # üîß –î–û–ë–ê–í–õ–Ø–ï–ú –ö–û–ù–ö–£–†–ï–ù–¢–ù–´–ô –ê–ù–ê–õ–ò–ó –ß–ï–†–ï–ó /get/in_similar
        try:
            from mpstats_api_fixed import mpstats_api
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            category_path = "/–î–ª—è –∂–µ–Ω—â–∏–Ω/–û–¥–µ–∂–¥–∞/–ü–ª–∞—Ç—å—è"  # Default category
            
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞
            if product_info and 'category' in product_info:
                category_path = product_info['category']
            elif product_info and 'name' in product_info:
                # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
                name_lower = product_info['name'].lower()
                if '–ø–ª–∞—Ç—å–µ' in name_lower or '—Å–∞—Ä–∞—Ñ–∞–Ω' in name_lower:
                    category_path = "/–î–ª—è –∂–µ–Ω—â–∏–Ω/–û–¥–µ–∂–¥–∞/–ü–ª–∞—Ç—å—è"
                elif '–æ–±—É–≤—å' in name_lower or '–∫—Ä–æ—Å—Å–æ–≤–∫–∏' in name_lower:
                    category_path = "/–î–ª—è –∂–µ–Ω—â–∏–Ω/–û–±—É–≤—å"
                elif '—Å—É–º–∫–∞' in name_lower:
                    category_path = "/–î–ª—è –∂–µ–Ω—â–∏–Ω/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã/–°—É–º–∫–∏"
            
            logger.info(f"üîç Getting competitive analysis for category: {category_path}")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π endpoint
            similar_data = await mpstats_api.get_in_similar(category_path)
            
            if similar_data and similar_data.get('data'):
                competitive_analysis = {
                    'category_path': category_path,
                    'total_competitors': similar_data.get('total', 0),
                    'competitors_sample': similar_data.get('data', [])[:5],  # –¢–æ–ø 5 –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
                    'market_insights': {
                        'api_response': 'success',
                        'data_source': 'mpstats_in_similar',
                        'last_updated': datetime.now().isoformat()
                    }
                }
                analysis['competitive_analysis'] = competitive_analysis
                logger.info(f"‚úÖ Added competitive analysis: {similar_data.get('total', 0)} competitors found")
            else:
                analysis['competitive_analysis'] = {
                    'category_path': category_path,
                    'total_competitors': 0,
                    'competitors_sample': [],
                    'market_insights': {
                        'api_response': 'empty_data',
                        'message': 'No competitors found in this category',
                        'data_source': 'mpstats_in_similar'
                    }
                }
                logger.info(f"‚ÑπÔ∏è No competitors found in category: {category_path}")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not get competitive analysis: {e}")
            analysis['competitive_analysis'] = {
                'error': str(e),
                'api_response': 'error'
            }
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'product', ?, 0)
            """,
            (email, f"–ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–∞ {request.article} (Fixed API)"),
        )
        conn.commit()
        conn.close()
        
        logger.info(f"‚úÖ Fixed product analysis completed for {request.article}")
        return analysis
        
    except Exception as e:
        logger.error(f"‚ùå Error in fixed product analysis for {request.article}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–≤–∞—Ä–∞: {str(e)}")

# –ê–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–∞
@app.post("/analysis/brand")
async def analyze_brand(request: BrandAnalysisRequest, email: str = Depends(get_current_user)):
    try:
        logger.info(f"Starting brand analysis for: {request.brand_name}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–∞
        brand_analysis = await get_brand_analysis(request.brand_name)
        
        if not brand_analysis:
            raise HTTPException(status_code=404, detail="Brand not found")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'brand', ?, 0)
            """,
            (email, f"–ê–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–∞ {request.brand_name}"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": brand_analysis["data"], **brand_analysis["data"]}

    except HTTPException as he:
        # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º 404 (–∏–ª–∏ –¥—Ä—É–≥–∏–µ) –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        raise he
    except Exception as e:
        logger.error(f"Error in brand analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error analyzing brand: {str(e)}")

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–∞ (–∫–∞–∫ –≤ –±–æ—Ç–µ)
@app.post("/analysis/brand/formatted")
async def analyze_brand_formatted(request: BrandAnalysisRequest, email: str = Depends(get_current_user)):
    try:
        logger.info(f"Starting formatted brand analysis for: {request.brand_name}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–∞
        brand_analysis = await get_brand_analysis(request.brand_name)
        
        if not brand_analysis:
            raise HTTPException(status_code=404, detail="Brand not found")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ –≤ –±–æ—Ç–µ
        return {
            "formatted_text": brand_analysis["formatted_text"],
            "data": brand_analysis["data"]
        }
        
    except Exception as e:
        logger.error(f"Error in formatted brand analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error analyzing brand: {str(e)}")

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ–∫–ª–∞–º—ã
@app.post("/planning/ad-monitoring")
async def monitor_ads(request: AdMonitoringRequest, email: str = Depends(get_current_user)):
    results = []
    total_spend = 0
    total_revenue = 0
    profitable_campaigns = 0
    
    for article in request.articles:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ
            product_info = await get_wb_product_info(article)
            
            if product_info:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                price = product_info['price']['current']
                daily_sales = product_info['sales']['today'] if product_info['sales']['today'] > 0 else max(1, product_info['feedbacks'] // 10)
                name = product_info['name']
            else:
                # –ó–∞–≥–ª—É—à–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                price = 1000 + len(article) * 50
                daily_sales = 5 + len(article) % 20
                name = f"–¢–æ–≤–∞—Ä {article}"
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∫–ª–∞–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            spend = daily_sales * price * 0.15  # 15% –æ—Ç –≤—ã—Ä—É—á–∫–∏ –Ω–∞ —Ä–µ–∫–ª–∞–º—É
            revenue = daily_sales * price
            roi = ((revenue - spend) / spend) * 100 if spend > 0 else 0
            
            total_spend += spend
            total_revenue += revenue
            
            if roi > 0:
                profitable_campaigns += 1
                if roi > 50:
                    status = "üü¢ –û—á–µ–Ω—å –ø—Ä–∏–±—ã–ª—å–Ω–∞—è"
                elif roi > 20:
                    status = "üü¢ –ü—Ä–∏–±—ã–ª—å–Ω–∞—è"
                else:
                    status = "üü° –ë–µ–∑—É–±—ã—Ç–æ—á–Ω–∞—è"
            else:
                status = "üî¥ –£–±—ã—Ç–æ—á–Ω–∞—è"
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º CTR –∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            impressions = int(daily_sales * 500)  # –ü—Ä–∏–º–µ—Ä–Ω–æ 500 –ø–æ–∫–∞–∑–æ–≤ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É
            clicks = int(impressions * 0.02)  # 2% CTR
            ctr = 2.0
            
            results.append({
                "article": article,
                "name": name,
                "spend": round(spend, 2),
                "revenue": round(revenue, 2),
                "roi": round(roi, 2),
                "clicks": clicks,
                "impressions": impressions,
                "ctr": ctr,
                "status": status
            })
            
        except Exception as e:
            logger.error(f"Error processing article {article}: {str(e)}")
            # –ó–∞–≥–ª—É—à–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            spend = 5000 + len(article) * 100
            revenue = spend * 1.2
            roi = 20.0
            
            total_spend += spend
            total_revenue += revenue
            profitable_campaigns += 1
            
            results.append({
                "article": article,
                "name": f"–¢–æ–≤–∞—Ä {article}",
                "spend": spend,
                "revenue": revenue,
                "roi": roi,
                "clicks": 1500,
                "impressions": 25000,
                "ctr": 6.0,
                "status": "üü¢ –ü—Ä–∏–±—ã–ª—å–Ω–∞—è"
            })
    
    total_roi = ((total_revenue - total_spend) / total_spend) * 100 if total_spend > 0 else 0
    
    return {
        "results": results,
        "summary": {
            "total_campaigns": len(request.articles),
            "profitable_campaigns": profitable_campaigns,
            "total_spend": round(total_spend, 2),
            "total_revenue": round(total_revenue, 2),
            "total_roi": round(total_roi, 2),
            "average_roi": round(sum(r["roi"] for r in results) / len(results), 2) if results else 0
        },
        "recommendations": [
            "–£–≤–µ–ª–∏—á–∏—Ç—å –±—é–¥–∂–µ—Ç –Ω–∞ –∫–∞–º–ø–∞–Ω–∏–∏ —Å ROI > 50%",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–π —Å ROI < 20%",
            "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –∫—Ä–µ–∞—Ç–∏–≤—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è CTR",
            "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –∫–∞–º–ø–∞–Ω–∏–π —Å ROI < 0%",
            "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Å–∏—é –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏"
        ]
    }

# –ù–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è
@app.get("/user/profile")
async def get_user_profile(email: str = Depends(get_current_user)):
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT email, balance, subscription_type, created_at, last_login, total_analyses
        FROM web_users WHERE email = ?
    ''', (email,))
    
    result = cursor.fetchone()
    conn.close()
    
    if not result:
        raise HTTPException(status_code=404, detail="User not found")
    
    return {
        "email": result[0],
        "balance": result[1],
        "subscription_type": result[2],
        "created_at": result[3],
        "last_login": result[4],
        "total_analyses": result[5]
    }

@app.get("/user/operations")
async def get_user_operations(email: str = Depends(get_current_user)):
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT id, type, description, amount, status, created_at
        FROM user_operations 
        WHERE user_email = ?
        ORDER BY created_at DESC
        LIMIT 50
    ''', (email,))
    
    operations = []
    for row in cursor.fetchall():
        operations.append({
            "id": row[0],
            "type": row[1],
            "description": row[2],
            "amount": row[3],
            "status": row[4],
            "date": row[5]
        })
    
    conn.close()
    return operations

@app.post("/user/change-password")
async def change_password(request: PasswordChangeRequest, email: str = Depends(get_current_user)):
    if len(request.new_password) < 6:
        raise HTTPException(status_code=400, detail="Password must be at least 6 characters long")
    
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    new_password_hash = hash_password(request.new_password)
    cursor.execute('''
        UPDATE web_users SET password_hash = ?
        WHERE email = ?
    ''', (new_password_hash, email))
    
    conn.commit()
    conn.close()
    
    return {"message": "Password changed successfully"}

@app.post("/user/upgrade-subscription")
async def upgrade_subscription(request: SubscriptionUpgradeRequest, email: str = Depends(get_current_user)):
    valid_plans = ["Free", "Pro", "Business"]
    if request.plan not in valid_plans:
        raise HTTPException(status_code=400, detail="Invalid subscription plan")
    
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –ø–æ–¥–ø–∏—Å–∫—É
    cursor.execute("SELECT subscription_type, balance FROM web_users WHERE email = ?", (email,))
    result = cursor.fetchone()
    
    if not result:
        raise HTTPException(status_code=404, detail="User not found")
    
    current_plan, balance = result
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–ª–∞–Ω–æ–≤
    plan_prices = {"Free": 0, "Pro": 1990, "Business": 4990}
    price = plan_prices[request.plan]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –¥–ª—è –ø–ª–∞—Ç–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤
    if price > 0 and balance < price:
        raise HTTPException(status_code=400, detail="Insufficient balance")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∫—É
    new_balance = balance - price if price > 0 else balance
    cursor.execute('''
        UPDATE web_users SET subscription_type = ?, balance = ?
        WHERE email = ?
    ''', (request.plan, new_balance, email))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
    if price > 0:
        cursor.execute('''
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, ?, ?, ?)
        ''', (email, "subscription", f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ {request.plan}", -price))
    
    conn.commit()
    conn.close()
    
    return {"message": f"Subscription upgraded to {request.plan}"}

@app.post("/user/add-balance")
async def add_balance(amount: float, email: str = Depends(get_current_user)):
    if amount <= 0:
        raise HTTPException(status_code=400, detail="Amount must be positive")
    
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        UPDATE web_users SET balance = balance + ?
        WHERE email = ?
    ''', (amount, email))
    
    cursor.execute('''
        INSERT INTO user_operations (user_email, type, description, amount)
        VALUES (?, ?, ?, ?)
    ''', (email, "payment", f"–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞", amount))
    
    conn.commit()
    conn.close()
    
    return {"message": f"Balance increased by {amount}‚ÇΩ"}

# –ê–Ω–∞–ª–∏–∑ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
@app.post("/analysis/supplier")
async def analyze_supplier(request: SupplierAnalysisRequest, email: str = Depends(get_current_user)):
    """Endpoint identical to bot's supplier analysis but returns JSON for frontend."""
    try:
        logger.info(f"Starting supplier analysis for: {request.supplier_name}")

        supplier_data = await get_supplier_analysis(request.supplier_name)

        if not supplier_data:
            raise HTTPException(status_code=404, detail="Supplier not found")

        # Log operation
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'supplier', ?, 0)
            """,
            (email, f"–ê–Ω–∞–ª–∏–∑ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ {request.supplier_name}"),
        )
        conn.commit()
        conn.close()

        camel = {
            "supplierName": supplier_data.get("supplierName"),
            "inn": supplier_data.get("inn"),
            "ogrn": supplier_data.get("ogrn"),
            "totalProducts": supplier_data.get("totalProducts"),
            "averagePrice": supplier_data.get("averagePrice"),
            "totalSales": supplier_data.get("totalSales"),
            "categories": supplier_data.get("categories"),
            "topProducts": supplier_data.get("topProducts"),
            "adActivity": supplier_data.get("adActivity", False),
            "recommendations": supplier_data.get("recommendations", [])
        }
        return {"success": True, "data": camel, **camel}

    except Exception as e:
        logger.error(f"Error in supplier analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error analyzing supplier: {str(e)}")

# –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–∫–∞—Ç–µ–≥–æ—Ä–∏–π)
@app.post("/analysis/category")
async def analyze_category(request: CategoryAnalysisRequest, email: str = Depends(get_current_user)):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ Wildberries –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π –±–æ—Ç—É (OracleQueries)."""
    try:
        month = request.month or datetime.utcnow().strftime("%Y-%m")
        logger.info(f"Starting category analysis for: {request.category_name} month={month}")

        data = await oracle.get_category_analysis(request.category_name, month, analysis_type="categories")

        if "error" in data:
            raise HTTPException(status_code=404, detail=data["error"])

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        summary_text = data.get("summary", "") if isinstance(data, dict) else ""
        recs = await generate_category_recommendations(summary_text)
        data["pluses"] = recs.get("pluses", [])
        data["minuses"] = recs.get("minuses", [])
        data["score"] = recs.get("score", 0)

        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'category', ?, 0)
            """,
            (email, f"–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {request.category_name}"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": data, **data}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in category analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error analyzing category: {str(e)}")

@app.post("/analysis/global-search")
async def analyze_global_search(request: GlobalSearchRequest, email: str = Depends(get_current_user)):
    """Performs social-media global search using Serper API (same as Telegram bot)."""
    try:
        logger.info(f"Starting global search for: {request.query}")

        results = await global_search_serper_detailed(request.query)
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤, –Ω–æ –Ω–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º 404,
        # —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –º–æ–≥ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ ¬´–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ¬ª

        # Log to user_operations for dashboard statistics
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'global_search', ?, 0)
            """,
            (email, f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ \"{request.query}\""),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": {"query": request.query, "results": results}}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in global search: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error performing global search: {str(e)}")

# –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
@app.post("/analysis/seasonality")
async def analyze_seasonality(request: SeasonalityAnalysisRequest, email: str = Depends(get_current_user)):
    """Returns seasonality analysis (annual & weekly) for the given WB category path."""
    try:
        logger.info(f"Starting seasonality analysis for: {request.category}")

        data = await get_seasonality_analysis(request.category)

        if "error" in data.get("annualData", {}):
            raise HTTPException(status_code=400, detail=data["annualData"]["error"])

        # Log operation in user_operations
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'seasonality', ?, 0)
            """,
            (email, f"–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {request.category}"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": data, **data}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in seasonality analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error analyzing seasonality: {str(e)}")

# ================================
#        AI HELPER ENDPOINT       
# ================================

@app.post("/analysis/ai-helper")
async def ai_helper(request: AIHelperRequest, email: str = Depends(get_current_user)):
    """Generate marketing content via OpenAI (same as Telegram bot AI helper)."""
    try:
        logger.info(f"AI helper generation request by {email}: {request.content_type}")

        generated_text = await generate_ai_content(request.content_type, request.prompt, OPENAI_API_KEY)

        # Log operation in user_operations ‚Äì zero cost for now
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'ai_helper', ?, 0)
            """,
            (email, f"AI helper ({request.content_type})"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": {"content": generated_text}}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in AI helper: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error generating AI content: {str(e)}")

# ================================
#        SUPPLY PLANNING          
# ================================

@app.post("/planning/supply-planning")
async def plan_supply(request: SupplyPlanningRequest, email: str = Depends(get_current_user)):
    """Return supply planning analysis for a list of WB articles."""
    try:
        if not request.articles:
            raise HTTPException(status_code=400, detail="No articles provided")

        logger.info(f"Starting supply planning for {len(request.articles)} articles")

        products_data = await supply_planner.analyze_multiple_products(request.articles)

        summary = format_supply_planning_report(products_data)

        # Log operation
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'supply_planning', ?, 0)
            """,
            (email, f"Supply planning for {len(request.articles)} items"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": {"products": products_data, "summary": summary}}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in supply planning: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in supply planning: {str(e)}")

# ================================
#    ENHANCED SUPPLY PLANNING     
# ================================

class EnhancedSupplyPlanningRequest(BaseModel):
    articles: List[str]
    target_stock_days: Optional[int] = 15  # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π —Ü–µ–ª–µ–≤–æ–π –∑–∞–ø–∞—Å

@app.post("/planning/supply-planning-enhanced")
async def enhanced_supply_planning(request: EnhancedSupplyPlanningRequest, email: str = Depends(get_current_user)):
    """Enhanced supply planning analysis with comprehensive metrics and real data integration."""
    try:
        if not request.articles:
            raise HTTPException(status_code=400, detail="No articles provided")
        
        if len(request.articles) > 50:
            raise HTTPException(status_code=400, detail="Maximum 50 articles allowed")

        logger.info(f"Enhanced supply planning by {email}: {len(request.articles)} articles, target days: {request.target_stock_days}")

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å
        from supply_planning_enhanced import enhanced_supply_planner, format_enhanced_supply_report
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ü–µ–ª–µ–≤–æ–π –∑–∞–ø–∞—Å
        if request.target_stock_days:
            enhanced_supply_planner.set_target_stock_days(request.target_stock_days)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        skus_data = await enhanced_supply_planner.analyze_multiple_skus(request.articles)
        
        # –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –¥–∞–∂–µ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏—á–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã
        if not skus_data:
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∑–∞–≥–ª—É—à–∫—É –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–µ–Ω–æ
            skus_data = [{
                "article": article,
                "brand": "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏",
                "product_name": f"–¢–æ–≤–∞—Ä {article} (–¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã)",
                "error": "–í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
            } for article in request.articles]
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        summary_analytics = enhanced_supply_planner.calculate_summary_analytics(skus_data)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        formatted_report = format_enhanced_supply_report(skus_data, summary_analytics)

        # Log operation
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'enhanced_supply_planning', ?, 0)
            """,
            (email, f"Enhanced supply planning for {len(request.articles)} SKUs"),
        )
        conn.commit()
        conn.close()

        return {
            "success": True, 
            "data": {
                "skus": skus_data,
                "summary": summary_analytics,
                "formatted_report": formatted_report,
                "total_skus": len(skus_data),
                "target_stock_days": request.target_stock_days
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in enhanced supply planning: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in enhanced supply planning: {str(e)}")

@app.post("/planning/supply-planning-export")
async def export_supply_planning(request: EnhancedSupplyPlanningRequest, email: str = Depends(get_current_user)):
    """Export enhanced supply planning data to CSV/Excel format."""
    try:
        if not request.articles:
            raise HTTPException(status_code=400, detail="No articles provided")

        logger.info(f"Supply planning export by {email}: {len(request.articles)} articles")

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å
        from supply_planning_enhanced import enhanced_supply_planner
        import pandas as pd
        import io
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ü–µ–ª–µ–≤–æ–π –∑–∞–ø–∞—Å
        if request.target_stock_days:
            enhanced_supply_planner.set_target_stock_days(request.target_stock_days)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        skus_data = await enhanced_supply_planner.analyze_multiple_skus(request.articles)
        
        if not skus_data:
            raise HTTPException(status_code=404, detail="No data found for export")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        export_data = []
        for sku in skus_data:
            export_row = {
                "–ê—Ä—Ç–∏–∫—É–ª": sku.get("article", ""),
                "–ë—Ä–µ–Ω–¥": sku.get("brand", ""),
                "–¢–æ–≤–∞—Ä": sku.get("product_name", ""),
                "–û—Å—Ç–∞—Ç–æ–∫ –Ω–∞ —Å–∫–ª–∞–¥–∞—Ö": sku.get("total_stock", 0),
                "–¢–æ–≤–∞—Ä –≤ —Ä–µ–∑–µ—Ä–≤–∞—Ö": sku.get("reserved_stock", 0),
                "–ü—Ä–æ–¥–∞–∂–∏ 7 –¥–Ω–µ–π": sku.get("sales_7d_units", 0),
                "–ü—Ä–æ–¥–∞–∂–∏ 30 –¥–Ω–µ–π": sku.get("sales_30d_units", 0),
                "–ü—Ä–æ–¥–∞–∂–∏ 60 –¥–Ω–µ–π": sku.get("sales_60d_units", 0),
                "–ü—Ä–æ–¥–∞–∂–∏ 90 –¥–Ω–µ–π": sku.get("sales_90d_units", 0),
                "–°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∏ –≤ –¥–µ–Ω—å": sku.get("avg_daily_sales", 0),
                "–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ 30 –¥–Ω–µ–π": sku.get("forecast_30d_units", 0),
                "–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å (–¥–Ω–∏)": sku.get("turnover_days", 0),
                "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –ø–æ—Å—Ç–∞–≤–∫–∞": sku.get("recommended_supply", 0),
                "–î–Ω–∏ –¥–æ OOS": sku.get("days_until_oos", 0),
                "–ó–∞–ø–∞—Å –≤ –¥–Ω—è—Ö": sku.get("available_days", 0),
                "–¢—Ä–µ–Ω–¥ –ø—Ä–æ–¥–∞–∂": sku.get("sales_trend", {}).get("trend_text", ""),
                "–ú–∞—Ä–∂–∞ –Ω–∞ —Ç–æ–≤–∞—Ä": sku.get("estimated_margin", 0),
                "–ü—Ä–æ—Ü–µ–Ω—Ç –≤ —Ä–µ–∫–ª–∞–º–µ": sku.get("ad_percentage", 0),
                "–ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ—Å—Ç–∞–≤–∫–∞": sku.get("last_supply_date", ""),
                "–í—ã—Ä—É—á–∫–∞ 30 –¥–Ω–µ–π": sku.get("revenue_30d", 0),
                "–í—ã—Ä—É—á–∫–∞ 60 –¥–Ω–µ–π": sku.get("revenue_60d", 0),
                "–í—ã—Ä—É—á–∫–∞ 90 –¥–Ω–µ–π": sku.get("revenue_90d", 0),
                "–°—Ç–∞—Ç—É—Å –æ—Å—Ç–∞—Ç–∫–æ–≤": sku.get("stock_status_text", ""),
                "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ—Å—Ç–∞–≤–∫–∏": sku.get("supply_priority_text", "")
            }
            export_data.append(export_row)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(export_data)
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        csv_content = csv_buffer.getvalue()
        
        # Log operation
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'supply_planning_export', ?, 0)
            """,
            (email, f"Supply planning export for {len(request.articles)} SKUs"),
        )
        conn.commit()
        conn.close()

        return {
            "success": True,
            "data": {
                "csv_content": csv_content,
                "filename": f"supply_planning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                "total_records": len(export_data)
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in supply planning export: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in supply planning export: {str(e)}")

# ================================
#        BLOGGER SEARCH           
# ================================

@app.post("/analysis/bloggers")
async def analyze_bloggers(request: BloggerSearchRequest, email: str = Depends(get_current_user)):
    """Search bloggers across platforms similar to Telegram bot."""
    try:
        if not request.query.strip():
            raise HTTPException(status_code=400, detail="Query is empty")

        logger.info(f"Starting blogger search for: {request.query}")

        results = await search_bloggers_by_query(request.query)
        summary_text = format_blogger_search_results(results)

        # Log operation
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'blogger_search', ?, 0)
            """,
            (email, f"Blogger search '{request.query}'"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": {"results": results, "summary": summary_text}}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in blogger search: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in blogger search: {str(e)}")

# ================================
#        EXTERNAL ANALYSIS        
# ================================

@app.post("/analysis/external")
async def analyze_external(request: ExternalAnalysisRequest, email: str = Depends(get_current_user)):
    """Analyze external ads and influencer posts for a product or keyword."""
    try:
        q = request.query.strip()
        if not q:
            raise HTTPException(status_code=400, detail="Query is empty")

        logger.info(f"Starting external analysis for: {q}")

        data = await get_external_ads_data(q)
        summary, _ = format_external_analysis(data)

        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'external_analysis', ?, 0)
            """,
            (email, f"External analysis '{q}'"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": {"results": data, "summary": summary}}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in external analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in external analysis: {str(e)}")

# ================================
#        ORACLE QUERIES           
# ================================

@app.post("/analysis/oracle-queries")
async def oracle_main(request: OracleMainRequest, email: str = Depends(get_current_user)):
    """–û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –û—Ä–∞–∫—É–ª–∞ (–ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ –∏ –±–æ—Ç."""
    try:
        if not (1 <= request.queries_count <= 5):
            raise HTTPException(status_code=400, detail="queries_count must be between 1 and 5")

        logger.info(
            f"Oracle queries by {email}: count={request.queries_count}, month={request.month}, "
            f"min_revenue={request.min_revenue}, min_freq={request.min_frequency}"
        )

        data = await oracle.get_search_queries_data(
            request.queries_count,
            request.month,
            request.min_revenue,
            request.min_frequency,
        )

        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'oracle_queries', ?, 0)
            """,
            (email, f"Oracle main {request.month} ({request.queries_count})"),
        )
        conn.commit()
        conn.close()

        return {"success": True, "data": data, **data}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in Oracle queries: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in Oracle queries: {str(e)}")

@app.post("/analysis/oracle-enhanced")
async def oracle_enhanced(request: EnhancedOracleRequest, email: str = Depends(get_current_user)):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –û—Ä–∞–∫—É–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    try:
        if not (1 <= request.queries_count <= 5):
            raise HTTPException(status_code=400, detail="queries_count must be between 1 and 5")
        
        valid_types = ["products", "brands", "suppliers", "categories", "search_queries"]
        if request.oracle_type not in valid_types:
            raise HTTPException(status_code=400, detail=f"oracle_type must be one of: {valid_types}")

        logger.info(
            f"Enhanced Oracle by {email}: type={request.oracle_type}, count={request.queries_count}, "
            f"month={request.month}, min_revenue={request.min_revenue}"
        )

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å
        try:
            from oracle_enhanced import EnhancedOracleQueries
            enhanced_oracle = EnhancedOracleQueries()
        except ImportError:
            # Fallback –∫ –æ–±—ã—á–Ω–æ–º—É –æ—Ä–∞–∫—É–ª—É –µ—Å–ª–∏ –Ω–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –º–æ–¥—É–ª—è
            logger.warning("Enhanced oracle module not found, using fallback")
            data = await oracle.get_search_queries_data(
                request.queries_count,
                request.month,
                request.min_revenue,
                request.min_frequency,
            )
            return {"success": True, "data": data, **data}

        # –í—ã–∑—ã–≤–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        data = await enhanced_oracle.get_enhanced_oracle_data(
            queries_count=request.queries_count,
            month=request.month,
            min_revenue=request.min_revenue,
            min_frequency=request.min_frequency,
            oracle_type=request.oracle_type,
            category_filter=request.category_filter,
            brand_filter=request.brand_filter,
            supplier_filter=request.supplier_filter
        )

        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO user_operations (user_email, type, description, amount)
            VALUES (?, 'oracle_enhanced', ?, 0)
            """,
            (email, f"Enhanced Oracle {request.oracle_type} {request.month} ({request.queries_count})"),
        )
        conn.commit()
        conn.close()

        return data

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in Enhanced Oracle: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in Enhanced Oracle: {str(e)}")

@app.post("/analysis/oracle-export")
async def oracle_export(
    request: EnhancedOracleRequest, 
    format_type: str = "csv",
    email: str = Depends(get_current_user)
):
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ä–∞–∫—É–ª–∞ –≤ CSV/Excel —Ñ–æ—Ä–º–∞—Ç"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        oracle_data = await oracle_enhanced(request, email)
        
        if not oracle_data.get("success"):
            raise HTTPException(status_code=400, detail="Failed to get oracle data")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        try:
            from oracle_enhanced import EnhancedOracleQueries
            enhanced_oracle = EnhancedOracleQueries()
            export_data = enhanced_oracle.generate_export_data(oracle_data, format_type)
        except ImportError:
            raise HTTPException(status_code=500, detail="Export functionality not available")
        
        return {
            "success": True,
            "export_data": export_data,
            "download_url": f"/download/{export_data['filename']}"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in Oracle export: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error in Oracle export: {str(e)}")

# Add the MPStats analysis routes
app.include_router(mpstats_router, prefix="/mpstats", tags=["MPStats Analysis"])
app.include_router(brand_router, prefix="/brand", tags=["Brand Analysis"])
app.include_router(category_router, prefix="/category", tags=["Category Analysis"])
app.include_router(blogger_router, prefix="/bloggers", tags=["Blogger Search"])
app.include_router(seller_router, prefix="/seller", tags=["Seller Analysis"])
app.include_router(oracle_router, prefix="/oracle", tags=["Oracle Analysis"])

if __name__ == "__main__":
    import uvicorn
    init_db()
    print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
