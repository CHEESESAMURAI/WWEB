import asyncio
import logging
from datetime import datetime, timedelta
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import uvicorn
import json
from typing import Dict, List, Optional
from main import ProductCardAnalyzer, TrendAnalyzer
from niche_analyzer import NicheAnalyzer
import sqlite3
import sys
import os
import aiohttp

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∫–∞—Ç–∞–ª–æ–≥ –≤ –ø—É—Ç—å –ø–æ–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.dirname(os.path.realpath(__file__)))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('api_server.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
try:
    product_analyzer = ProductCardAnalyzer()
    trend_analyzer = TrendAnalyzer()
    niche_analyzer = NicheAnalyzer()
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ new_bot.py –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MPSTAT
    from new_bot import get_wb_product_info, global_search_serper_detailed, get_mpsta_data, format_mpsta_results
    logger.info("–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: {str(e)}")
    product_analyzer = None
    trend_analyzer = None
    niche_analyzer = None

app = FastAPI()

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ProductRequest(BaseModel):
    article: str

class NicheRequest(BaseModel):
    keyword: str

class CategoryAnalysisRequest(BaseModel):
    category_path: str
    date_from: str
    date_to: str
    fbs: int = 0

class SearchRequest(BaseModel):
    query: str
    max_results: int = 10
    include_social: bool = True
    include_news: bool = False
    include_images: bool = False

class TrackRequest(BaseModel):
    user_id: int
    article: str

class RefreshRequest(BaseModel):
    user_id: int
    article_id: int

# –î–æ–±–∞–≤–ª—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MPStats API –∫–∞—Ç–µ–≥–æ—Ä–∏–π
async def fetch_mpstats_category_data(category_path: str, date_from: str, date_to: str, fbs: int) -> Dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ MPStats API"""
    
    url = "https://mpstats.io/api/wb/get/category"
    params = {
        "d1": date_from,
        "d2": date_to,
        "path": category_path,
        "fbs": fbs
    }
    
    headers = {
        "X-Mpstats-TOKEN": "68431d2ac72ea4.96910328a56006b24a55daf65db03835d5fe5b4d",
        "Content-Type": "application/json"
    }
    
    logger.info(f"üöÄ Fetching category data for {category_path}: {url} with params {params}")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers=headers, timeout=aiohttp.ClientTimeout(total=30)) as response:
                logger.info(f"üìä MPStats category response: {response.status}")
                
                if response.status == 401:
                    error_data = await response.json()
                    logger.error(f"‚ùå MPStats API unauthorized: {error_data}")
                    raise HTTPException(status_code=401, detail="MPStats API authorization failed. Please check your API token.")
                
                elif response.status == 404:
                    logger.error(f"‚ùå Category not found: {category_path}")
                    raise HTTPException(status_code=404, detail=f"Category '{category_path}' not found in MPStats.")
                
                elif response.status != 200:
                    error_text = await response.text()
                    logger.error(f"‚ùå MPStats API error {response.status}: {error_text}")
                    raise HTTPException(status_code=500, detail=f"MPStats API error: {response.status}")
                
                data = await response.json()
                logger.info(f"‚úÖ Successfully fetched category data: {len(data.get('data', []))} products")
                return data
                
    except aiohttp.ClientError as e:
        logger.error(f"‚ùå Network error: {e}")
        raise HTTPException(status_code=500, detail=f"Network error when connecting to MPStats API: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {e}")
        raise HTTPException(status_code=500, detail=f"Unexpected error: {str(e)}")

def process_category_analysis(category_path: str, date_from: str, date_to: str, products: List[Dict]) -> Dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    
    import statistics
    
    if not products:
        return {
            "category_info": {
                "name": category_path,
                "period": f"{date_from} - {date_to}",
                "total_products": 0,
                "total_revenue": 0,
                "total_sales": 0,
                "average_price": 0,
                "average_rating": 0,
                "average_purchase": 0,
                "average_turnover_days": 0
            },
            "top_products": [],
            "all_products": [],
            "category_metrics": {
                "revenue_per_product": 0,
                "sales_per_product": 0,
                "products_with_sales_percentage": 0,
                "fbs_percentage": 0,
                "average_comments": 0,
                "top_brands_count": 0,
                "price_range_min": 0,
                "price_range_max": 0
            },
            "aggregated_charts": {
                "sales_graph": {"dates": [], "values": []},
                "stocks_graph": {"dates": [], "values": []},
                "price_graph": {"dates": [], "values": []},
                "visibility_graph": {"dates": [], "values": []}
            },
            "metadata": {
                "processing_info": {
                    "data_source": "MPStats API",
                    "processing_timestamp": datetime.now().isoformat(),
                    "total_products_found": 0,
                    "period": f"{date_from} to {date_to}",
                }
            }
        }
    
    total_products = len(products)
    total_revenue = sum(product.get('revenue', 0) for product in products)
    total_sales = sum(product.get('sales', 0) for product in products)
    
    prices = [product.get('final_price', 0) for product in products if product.get('final_price', 0) > 0]
    average_price = statistics.mean(prices) if prices else 0
    
    ratings = [product.get('rating', 0) for product in products if product.get('rating', 0) > 0]
    average_rating = statistics.mean(ratings) if ratings else 0
    
    purchases = [product.get('purchase', 0) for product in products if product.get('purchase', 0) > 0]
    average_purchase = statistics.mean(purchases) if purchases else 0
    
    turnover_days = [product.get('turnover_days', 0) for product in products if product.get('turnover_days', 0) > 0]
    average_turnover_days = statistics.mean(turnover_days) if turnover_days else 0
    
    # –¢–æ–ø —Ç–æ–≤–∞—Ä—ã –ø–æ –≤—ã—Ä—É—á–∫–µ
    sorted_products = sorted(products, key=lambda x: x.get('revenue', 0), reverse=True)
    top_products = sorted_products[:10]
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    products_with_sales = len([p for p in products if p.get('sales', 0) > 0])
    products_with_sales_percentage = (products_with_sales / total_products) * 100
    
    fbs_products = len([p for p in products if p.get('fbs', False)])
    fbs_percentage = (fbs_products / total_products) * 100
    
    total_comments = sum(product.get('comments', 0) for product in products)
    average_comments = total_comments / total_products
    
    brands = set(product.get('brand', '') for product in products if product.get('brand'))
    top_brands_count = len(brands)
    
    price_range_min = min(prices) if prices else 0
    price_range_max = max(prices) if prices else 0
    
    # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
    all_dates = set()
    for product in products:
        if 'graph' in product and isinstance(product['graph'], dict):
            all_dates.update(product['graph'].keys())
    
    sorted_dates = sorted(list(all_dates))
    
    sales_data = []
    stocks_data = []
    price_data = []
    visibility_data = []
    
    for date in sorted_dates:
        # –ü—Ä–æ–¥–∞–∂–∏
        daily_sales = sum(
            product.get('graph', {}).get(date, 0) 
            for product in products 
            if isinstance(product.get('graph'), dict)
        )
        sales_data.append(daily_sales)
        
        # –û—Å—Ç–∞—Ç–∫–∏
        daily_stocks = sum(
            product.get('stocks_graph', {}).get(date, 0) 
            for product in products 
            if isinstance(product.get('stocks_graph'), dict)
        )
        stocks_data.append(daily_stocks)
        
        # –¶–µ–Ω—ã (—Å—Ä–µ–¥–Ω–∏–µ)
        daily_prices = [
            product.get('price_graph', {}).get(date, 0)
            for product in products 
            if isinstance(product.get('price_graph'), dict) and product.get('price_graph', {}).get(date, 0) > 0
        ]
        avg_price = statistics.mean(daily_prices) if daily_prices else 0
        price_data.append(avg_price)
        
        # –í–∏–¥–∏–º–æ—Å—Ç—å
        daily_visibility = sum(
            product.get('product_visibility_graph', {}).get(date, 0) 
            for product in products 
            if isinstance(product.get('product_visibility_graph'), dict)
        )
        visibility_data.append(daily_visibility)
    
    return {
        "category_info": {
            "name": category_path,
            "period": f"{date_from} - {date_to}",
            "total_products": total_products,
            "total_revenue": total_revenue,
            "total_sales": total_sales,
            "average_price": round(average_price, 2),
            "average_rating": round(average_rating, 2),
            "average_purchase": round(average_purchase, 2),
            "average_turnover_days": round(average_turnover_days, 1)
        },
        "top_products": top_products,
        "all_products": products,
        "category_metrics": {
            "revenue_per_product": round(total_revenue / total_products, 2),
            "sales_per_product": round(total_sales / total_products, 2),
            "products_with_sales_percentage": round(products_with_sales_percentage, 1),
            "fbs_percentage": round(fbs_percentage, 1),
            "average_comments": round(average_comments, 1),
            "top_brands_count": top_brands_count,
            "price_range_min": price_range_min,
            "price_range_max": price_range_max
        },
        "aggregated_charts": {
            "sales_graph": {"dates": sorted_dates, "values": sales_data},
            "stocks_graph": {"dates": sorted_dates, "values": stocks_data},
            "price_graph": {"dates": sorted_dates, "values": price_data},
            "visibility_graph": {"dates": sorted_dates, "values": visibility_data}
        },
        "metadata": {
            "processing_info": {
                "data_source": "MPStats API",
                "processing_timestamp": datetime.now().isoformat(),
                "total_products_found": len(products),
                "period": f"{date_from} to {date_to}",
            }
        }
    }

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤
def init_db():
    try:
        conn = sqlite3.connect('tracked_articles.db')
        cursor = conn.cursor()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS tracked_articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            article TEXT,
            name TEXT,
            price REAL,
            stock INTEGER,
            sales_total INTEGER,
            sales_per_day REAL,
            last_updated TEXT,
            UNIQUE(user_id, article)
        )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

# –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã API

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
    return {
        "status": "ok", 
        "timestamp": datetime.now().isoformat(),
        "analyzers": {
            "product_analyzer": product_analyzer is not None,
            "trend_analyzer": trend_analyzer is not None,
            "niche_analyzer": niche_analyzer is not None
        }
    }

@app.get("/extended_analysis/{article}")
async def get_product_analysis(article: str):
    """–ê–Ω–∞–ª–∏–∑ —Ç–æ–≤–∞—Ä–∞ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É"""
    try:
        logger.info(f"–ó–∞–ø—Ä–æ—Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–≤–∞—Ä–∞: {article}")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API Wildberries
        result = await get_wb_product_info(article)
        if not result:
            logger.error(f"–¢–æ–≤–∞—Ä —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º {article} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            raise HTTPException(status_code=404, detail=f"–¢–æ–≤–∞—Ä —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º {article} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ Wildberries")
        
        # –ï—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ, –æ–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ MPSTAT
        try:
            mpsta_data = await get_mpsta_data(article)
            if mpsta_data and not mpsta_data.get("error"):
                mpsta_formatted = format_mpsta_results(mpsta_data)
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                result.update({
                    "mpstat_data": mpsta_formatted
                })
                logger.info(f"–î–∞–Ω–Ω—ã–µ MPSTAT –¥–æ–±–∞–≤–ª–µ–Ω—ã –∫ –∞–Ω–∞–ª–∏–∑—É —Ç–æ–≤–∞—Ä–∞ {article}")
        except Exception as mpsta_error:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ MPSTAT –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {article}: {str(mpsta_error)}")
        
        return result
    except HTTPException as he:
        logger.error(f"HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–æ–≤–∞—Ä–∞ {article}: {str(he.detail)}")
        raise he
    except Exception as e:
        logger.error(f"Error analyzing product {article}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze_niche")
async def analyze_niche(request: NicheRequest):
    """–ê–Ω–∞–ª–∏–∑ –Ω–∏—à–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
    try:
        logger.info(f"–ó–∞–ø—Ä–æ—Å –∞–Ω–∞–ª–∏–∑–∞ –Ω–∏—à–∏: {request.keyword}")
        if not niche_analyzer:
            raise HTTPException(status_code=503, detail="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∏—à –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            
        result = await niche_analyzer.analyze_category(request.keyword)
        if not result:
            raise HTTPException(status_code=404, detail="–ù–∏—à–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ MPSTAT
        try:
            mpsta_data = await get_mpsta_data(request.keyword)
            if mpsta_data and not mpsta_data.get("error"):
                mpsta_formatted = format_mpsta_results(mpsta_data)
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                result.update({
                    "mpstat_data": mpsta_formatted
                })
                logger.info(f"–î–∞–Ω–Ω—ã–µ MPSTAT –¥–æ–±–∞–≤–ª–µ–Ω—ã –∫ –∞–Ω–∞–ª–∏–∑—É –Ω–∏—à–∏ {request.keyword}")
        except Exception as mpsta_error:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ MPSTAT –¥–ª—è –Ω–∏—à–∏ {request.keyword}: {str(mpsta_error)}")
        
        return result
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error(f"Error analyzing niche {request.keyword}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze_category")
async def analyze_category(request: NicheRequest):
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
    try:
        logger.info(f"–ó–∞–ø—Ä–æ—Å –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {request.keyword}")
        if not niche_analyzer:
            raise HTTPException(status_code=503, detail="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∏—à –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            
        result = await niche_analyzer.analyze_category(request.keyword)
        if not result:
            raise HTTPException(status_code=404, detail="–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ MPSTAT
        try:
            mpsta_data = await get_mpsta_data(request.keyword)
            if mpsta_data and not mpsta_data.get("error"):
                mpsta_formatted = format_mpsta_results(mpsta_data)
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                result.update({
                    "mpstat_data": mpsta_formatted
                })
                logger.info(f"–î–∞–Ω–Ω—ã–µ MPSTAT –¥–æ–±–∞–≤–ª–µ–Ω—ã –∫ –∞–Ω–∞–ª–∏–∑—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {request.keyword}")
        except Exception as mpsta_error:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ MPSTAT –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {request.keyword}: {str(mpsta_error)}")
        
        return result
    except Exception as e:
        logger.error(f"Error analyzing category {request.keyword}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/category-analysis")
async def comprehensive_category_analysis(request: CategoryAnalysisRequest):
    """–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ MPStats"""
    try:
        logger.info(f"üéØ Comprehensive category analysis request: {request.category_path}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ MPStats API
        mpstats_data = await fetch_mpstats_category_data(
            request.category_path, 
            request.date_from, 
            request.date_to, 
            request.fbs
        )
        
        products = mpstats_data.get('data', [])
        
        if not products:
            logger.warning(f"‚ö†Ô∏è No products found for category: {request.category_path}")
            raise HTTPException(status_code=404, detail=f"No products found for category '{request.category_path}' in the specified period.")
        
        logger.info(f"üìä Processing {len(products)} products for category analysis")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        result = process_category_analysis(request.category_path, request.date_from, request.date_to, products)
        
        logger.info(f"‚úÖ Category analysis completed successfully for: {request.category_path}")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in category analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@app.post("/search")
async def search(request: SearchRequest):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤"""
    try:
        logger.info(f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {request.query}")
        # –ù–∞–ø—Ä—è–º—É—é –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏–∑ new_bot.py
        result = await global_search_serper_detailed(request.query)
        return result
    except Exception as e:
        logger.error(f"Error searching for {request.query}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/tracked_items")
async def get_tracked_items(user_id: int):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        conn = sqlite3.connect('tracked_articles.db')
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT id, article, name, price, stock, sales_total, sales_per_day, last_updated 
        FROM tracked_articles 
        WHERE user_id = ?
        ''', (user_id,))
        
        items = []
        for row in cursor.fetchall():
            items.append({
                'id': row[0],
                'article': row[1],
                'name': row[2],
                'price': row[3],
                'stock': row[4],
                'salesTotal': row[5],
                'salesPerDay': row[6],
                'lastUpdated': row[7]
            })
        
        conn.close()
        return items
    except Exception as e:
        logger.error(f"Error getting tracked items for user {user_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/track_item")
async def track_item(request: TrackRequest):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ new_bot.py
        product_info = await get_wb_product_info(request.article)
        if not product_info:
            raise HTTPException(status_code=404, detail="–¢–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        conn = sqlite3.connect('tracked_articles.db')
        cursor = conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ —É–∂–µ —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä
        cursor.execute('SELECT id FROM tracked_articles WHERE user_id = ? AND article = ?', 
                      (request.user_id, request.article))
        
        if cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=400, detail="–≠—Ç–æ—Ç —Ç–æ–≤–∞—Ä —É–∂–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –∏–∑ product_info
        price = product_info.get('price', {}).get('current', 0)
        if isinstance(product_info.get('price'), (int, float)):
            price = product_info.get('price', 0)
            
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
        sales_total = product_info.get('sales', {}).get('total', 0)
        sales_per_day = product_info.get('sales', {}).get('today', 0)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
        stock = product_info.get('stocks', {}).get('total', 0)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä –≤ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ
        cursor.execute('''
        INSERT INTO tracked_articles (user_id, article, name, price, stock, sales_total, sales_per_day, last_updated)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            request.user_id,
            request.article,
            product_info.get('name', f'–¢–æ–≤–∞—Ä {request.article}'),
            price,
            stock,
            sales_total,
            sales_per_day,
            datetime.now().isoformat()
        ))
        
        conn.commit()
        last_id = cursor.lastrowid
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä
        cursor.execute('''
        SELECT id, article, name, price, stock, sales_total, sales_per_day, last_updated 
        FROM tracked_articles 
        WHERE id = ?
        ''', (last_id,))
        
        row = cursor.fetchone()
        conn.close()
        
        return {
            'id': row[0],
            'article': row[1],
            'name': row[2],
            'price': row[3],
            'stock': row[4],
            'salesTotal': row[5],
            'salesPerDay': row[6],
            'lastUpdated': row[7]
        }
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error tracking item {request.article}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/untrack_item")
async def untrack_item(user_id: int, article_id: int):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö"""
    try:
        conn = sqlite3.connect('tracked_articles.db')
        cursor = conn.cursor()
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–≤–∞—Ä
        cursor.execute('DELETE FROM tracked_articles WHERE user_id = ? AND id = ?', 
                      (user_id, article_id))
        
        if cursor.rowcount == 0:
            conn.close()
            raise HTTPException(status_code=404, detail="–¢–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        conn.commit()
        conn.close()
        
        return {"success": True}
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error untracking item {article_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/refresh_tracked_item")
async def refresh_tracked_item(request: RefreshRequest):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞"""
    try:
        conn = sqlite3.connect('tracked_articles.db')
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        cursor.execute('SELECT article FROM tracked_articles WHERE id = ? AND user_id = ?', 
                      (request.article_id, request.user_id))
        
        row = cursor.fetchone()
        if not row:
            conn.close()
            raise HTTPException(status_code=404, detail="–¢–æ–≤–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        article = row[0]
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ new_bot.py
        product_info = await get_wb_product_info(article)
        if not product_info:
            raise HTTPException(status_code=404, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –∏–∑ product_info
        price = product_info.get('price', {}).get('current', 0)
        if isinstance(product_info.get('price'), (int, float)):
            price = product_info.get('price', 0)
            
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
        sales_total = product_info.get('sales', {}).get('total', 0)
        sales_per_day = product_info.get('sales', {}).get('today', 0)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
        stock = product_info.get('stocks', {}).get('total', 0)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        cursor.execute('''
        UPDATE tracked_articles 
        SET price = ?, stock = ?, sales_total = ?, sales_per_day = ?, last_updated = ?
        WHERE id = ? AND user_id = ?
        ''', (
            price,
            stock,
            sales_total,
            sales_per_day,
            datetime.now().isoformat(),
            request.article_id,
            request.user_id
        ))
        
        conn.commit()
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        cursor.execute('''
        SELECT id, article, name, price, stock, sales_total, sales_per_day, last_updated 
        FROM tracked_articles 
        WHERE id = ?
        ''', (request.article_id,))
        
        row = cursor.fetchone()
        conn.close()
        
        return {
            'id': row[0],
            'article': row[1],
            'name': row[2],
            'price': row[3],
            'stock': row[4],
            'salesTotal': row[5],
            'salesPerDay': row[6],
            'lastUpdated': row[7]
        }
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error refreshing item {request.article_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    init_db()
    uvicorn.run(app, host="0.0.0.0", port=8000) 